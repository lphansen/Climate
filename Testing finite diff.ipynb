{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pricing Uncertainty Induced by Climate Change\n",
    "by [Michael Barnett](https://sites.google.com/site/michaelduglasbarnett/home), [William Brock](https://www.ssc.wisc.edu/~wbrock/) and [Lars Peter Hansen](https://larspeterhansen.org/).\n",
    "\n",
    "The latest draft of the paper can be found [here](https://larspeterhansen.org/research/papers/).\n",
    "\n",
    "Notebook by: Jiaming Wang\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides the source code and explanations for how we solve the model setting with __climate damages to consumption__. Users can find computational details for the model setting with __climate damages to growth__ in the notebook for the [Growth Damages Model](GrowthModel.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Code-and-Illustration\" data-toc-modified-id=\"Code-and-Illustration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code and Illustration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Choosing-key-parameters\" data-toc-modified-id=\"Choosing-key-parameters-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Choosing key parameters</a></span></li><li><span><a href=\"#Solving-the-HJB-equation-with-consumption-damages\" data-toc-modified-id=\"Solving-the-HJB-equation-with-consumption-damages-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Solving the HJB equation with consumption damages</a></span></li></ul></li><li><span><a href=\"#Previous-solver\" data-toc-modified-id=\"Previous-solver-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Previous solver</a></span></li><li><span><a href=\"#Assembling-matrix-in-python\" data-toc-modified-id=\"Assembling-matrix-in-python-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Assembling matrix in python</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Remark:-Choices-of-model-hyper-parameters\" data-toc-modified-id=\"Remark:-Choices-of-model-hyper-parameters-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Remark: Choices of model hyper parameters</a></span></li><li><span><a href=\"#Remark:-Discretization-of-state-spaces\" data-toc-modified-id=\"Remark:-Discretization-of-state-spaces-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Remark: Discretization of state spaces</a></span></li><li><span><a href=\"#Remark:-Accounting-for-uncertainty-about-consumption-damages\" data-toc-modified-id=\"Remark:-Accounting-for-uncertainty-about-consumption-damages-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>Remark: Accounting for uncertainty about consumption damages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Low-damage-model\" data-toc-modified-id=\"Low-damage-model-4.0.3.1\"><span class=\"toc-item-num\">4.0.3.1&nbsp;&nbsp;</span>Low damage model</a></span></li><li><span><a href=\"#High-damage-model\" data-toc-modified-id=\"High-damage-model-4.0.3.2\"><span class=\"toc-item-num\">4.0.3.2&nbsp;&nbsp;</span>High damage model</a></span></li><li><span><a href=\"#Distorted-model-probabilities\" data-toc-modified-id=\"Distorted-model-probabilities-4.0.3.3\"><span class=\"toc-item-num\">4.0.3.3&nbsp;&nbsp;</span>Distorted model probabilities</a></span></li><li><span><a href=\"#Weighted-damage-models\" data-toc-modified-id=\"Weighted-damage-models-4.0.3.4\"><span class=\"toc-item-num\">4.0.3.4&nbsp;&nbsp;</span>Weighted damage models</a></span></li></ul></li><li><span><a href=\"#Remark:--Details-for-solving-HJB-PDE\" data-toc-modified-id=\"Remark:--Details-for-solving-HJB-PDE-4.0.4\"><span class=\"toc-item-num\">4.0.4&nbsp;&nbsp;</span>Remark:  Details for solving HJB PDE</a></span></li><li><span><a href=\"#Remark:-Conjugate-gradient-solver-for-linear-system\" data-toc-modified-id=\"Remark:-Conjugate-gradient-solver-for-linear-system-4.0.5\"><span class=\"toc-item-num\">4.0.5&nbsp;&nbsp;</span>Remark: Conjugate gradient solver for linear system</a></span></li><li><span><a href=\"#Remark:-PDE-boundary-conditions\" data-toc-modified-id=\"Remark:-PDE-boundary-conditions-4.0.6\"><span class=\"toc-item-num\">4.0.6&nbsp;&nbsp;</span>Remark: PDE boundary conditions</a></span></li><li><span><a href=\"#Remark:-Tolerance-level-and-conergence-criteria-for-HJB\" data-toc-modified-id=\"Remark:-Tolerance-level-and-conergence-criteria-for-HJB-4.0.7\"><span class=\"toc-item-num\">4.0.7&nbsp;&nbsp;</span>Remark: Tolerance level and conergence criteria for HJB</a></span></li><li><span><a href=\"#Remark:-Solving-time-and-error-analysis\" data-toc-modified-id=\"Remark:-Solving-time-and-error-analysis-4.0.8\"><span class=\"toc-item-num\">4.0.8&nbsp;&nbsp;</span>Remark: Solving time and error analysis</a></span></li></ul></li><li><span><a href=\"#Simulation\" data-toc-modified-id=\"Simulation-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Simulation</a></span></li><li><span><a href=\"#SCC-Calculation-Feyman-Kac\" data-toc-modified-id=\"SCC-Calculation-Feyman-Kac-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>SCC Calculation Feyman Kac</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remark:-Convergence-criteria-for-Feyman-Kac\" data-toc-modified-id=\"Remark:-Convergence-criteria-for-Feyman-Kac-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Remark: Convergence criteria for Feyman Kac</a></span></li></ul></li><li><span><a href=\"#Probabilities\" data-toc-modified-id=\"Probabilities-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Probabilities</a></span></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implied-worst-case-densities\" data-toc-modified-id=\"Implied-worst-case-densities-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Implied worst case densities</a></span></li><li><span><a href=\"#SCC-Decomposition\" data-toc-modified-id=\"SCC-Decomposition-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>SCC Decomposition</a></span></li><li><span><a href=\"#Emission-trajectory\" data-toc-modified-id=\"Emission-trajectory-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Emission trajectory</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code and Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:07:18.018395Z",
     "start_time": "2021-03-26T14:07:12.421582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from supportfunctions import *\n",
    "sys.stdout.flush()\n",
    "import petsc4py\n",
    "petsc4py.init(sys.argv)\n",
    "from petsc4py import PETSc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:07:18.035320Z",
     "start_time": "2021-03-26T14:07:18.020388Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'BBH_model1_Weighted_Averse'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Damage function choices\n",
    "damageSpec = 'Weighted'  # Choose among \"High\"(Weitzman), 'Low'(Nordhaus) and 'Weighted' (arithmeticAverage of the two)\n",
    "\n",
    "if damageSpec == 'High':\n",
    "    weight = 0.0\n",
    "elif damageSpec == 'Low':\n",
    "    weight = 1.0\n",
    "else:\n",
    "    weight = 0.5\n",
    "\n",
    "Œæp =  1 / 4000  # Ambiguity Averse Paramter \n",
    "# We stored solutions for Œæp =  1 / 4000 to which we referred as \"Ambiguity Averse\" and Œæp = 1000 as ‚ÄúAmbiguity Neutral‚Äù in the paper\n",
    "# Sensible choices are from 0.0002 to 4000, while for parameters input over 0.01 the final results won't alter as much\n",
    "\n",
    "if Œæp < 1:\n",
    "    aversespec = \"Averse\"\n",
    "else:\n",
    "    aversespec = 'Neutral'\n",
    "\n",
    "smart_guess = False\n",
    "model = 'model1'\n",
    "filename = 'BBH_' + model + '_' + damageSpec + '_' + aversespec\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:07:18.042303Z",
     "start_time": "2021-03-26T14:07:18.037315Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Loading Smart guesses\n",
    "# # Do Not run this cell if you don't want to use smart guesses, it might take longer than 18 hours. See remarks in section 2.2.8\n",
    "# guess = pickle.load(open('./data/{}guess.pickle'.format(damageSpec + aversespec), \"rb\", -1))\n",
    "# v0_guess = guess['v0']\n",
    "# q_guess = guess['q']\n",
    "# e_guess = guess['e']\n",
    "# # base_guess = guess['base']\n",
    "# # worst_guess = guess['worst']\n",
    "# smart_guess = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HJB equation with consumption damages\n",
    "\n",
    "We now outline the code used to solve the HJB equation for the damages to consumption model. We summarize the steps for the numerical algorithm and refer to those steps in the code below. More details are provided in the remarks.\n",
    "\n",
    "To solve the nonlinear partial differential equations that characterize the HJB equations for the planner's problems for our model, we use a so-called implicit, finite-difference scheme and a conjugate gradient method. Consultations with Joseph Huang, Paymon Khorrami and Fabrice Tourre played an important role in the software implementation. We briefly outline the steps to this numerical solution method below.\n",
    "\n",
    "Recall that the HJB equation of interest for the consumption damages model includes both minimization and maximization:\n",
    "\n",
    "\\begin{align*} 0 = \\max_{a \\in {\\mathbb A}} \\min_{q > 0, \\int q P(d\\theta) =1 } \\min_{g \\in {\\mathbb R}^m} & - \\delta V(x)  + \\delta (1 - \\kappa) \\left[ \\log \\left( {\\alpha}  - i - j \\right)\n",
    "+ k -  d   \\right] + \\delta \\kappa \\left( \\log e +  r \\right) \\cr &\n",
    "+ {\\frac {\\partial V}{\\partial x}} (x) \\cdot \\left[\\int_\\Theta  \\mu_X(x,a \\mid \\theta) q(\\theta) P(d\\theta)  + \\sigma_X(x) g\\right] \\cr &\n",
    "+{\\frac 1 2} \\textrm{trace} \\left[\\sigma_X(x)' {\\frac {\\partial^2 V}{\\partial x \\partial x'}}(x) \\sigma_X(x) \\right] \\cr &\n",
    "+ {\\frac {\\xi_m} 2} g'g + \\xi_p \\int_\\Theta [\\log q(\\theta)]  q(\\theta) P(d \\theta).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed recursively as follows:\n",
    "\n",
    "\n",
    "1) start with a value function guess ${\\widetilde V}(x)$ and a decision function ${\\widetilde a}(x)$;\n",
    "\n",
    "2) given $({\\widetilde V}, {\\widetilde a})$, solve the minimization problem embedded in the HJB equation and produce an exponentially-tilted  density ${\\widehat  q}$ and drift distortion ${\\widehat g}$  conditioned on $x$ and  using the  approach described   in section D of [Online Appendix](http://larspeterhansen.org/wp-content/uploads/2020/01/RFSPaper_BBH_final_appendix.pdf);\n",
    "\n",
    "3) compute the implied relative entropy from the change in prior:\n",
    "$$\n",
    "{\\widehat {\\mathbb I}}(x) = \\int_\\Theta [\\log {\\widehat q}(\\theta)]  {\\widehat q}(\\theta) P(d \\theta);\n",
    "$$\n",
    "\n",
    "4)  solve the following maximization problem by choice of $a=(i,j,e)$:\n",
    "\n",
    "\\begin{align*}\n",
    "& \\delta (1 - \\kappa)  \\log \\left( {\\alpha}  - i - j \\right)\n",
    " + \\delta \\kappa  \\log e   \\cr &\n",
    "+ {\\frac {\\partial V}{\\partial x}} (x) \\cdot \\int_\\Theta  \\mu_X\\left(x,a   \\mid \\theta \\right) {\\widehat q}(\\theta \\mid x ) P(d\\theta);\n",
    "\\end{align*}\n",
    "\n",
    "   a) Compute ${\\hat i}$ and ${\\hat j}$ by solving the two first-order conditions for $i$ and $j$ with cobweb-style iterations.  Cobweb iterations converge or diverge depending the relative slopes of supply and demand functions.  By shrinking the step size, these slopes can be altered.\n",
    "\n",
    "Expand the two equation system by adding a third equation that defines  a common \"price\" $p$,\n",
    "$$\n",
    "p =  {\\frac {\\delta (1-\\kappa)}  {\\alpha  - i - j} } = g(i+j).\n",
    "$$\n",
    "Write the two first-order conditions as\n",
    "$$\n",
    "p = {\\frac {\\phi_0 \\phi_1 V_k(x) }{ 1 + \\phi_1 i}} = f_1(i)\n",
    "$$\n",
    "$$\n",
    "p  = V_r(x)  \\left(  {\\psi_0 \\psi_1} \\right) j^{\\psi_1 - 1}  \\exp\\left[ \\psi_1(k -  r)\\right]  = f_2(j).\n",
    "$$\n",
    "\n",
    "Given $p$  and for step size $\\tilde{\\epsilon}$, compute\n",
    "\n",
    "* $i^* = (f_1)^{-1}(p)$\n",
    "\n",
    "* $j^* = (f_2)^{-1}(p)$\n",
    "\n",
    "* $p^* = {\\eta} g(i^* + j^*) + \\left(1 - {\\eta} \\right) p$\n",
    "\n",
    "* set $p  = p^*$.\n",
    "\n",
    "Iterate to convergence.\n",
    "\n",
    "\n",
    "b) Compute ${\\hat e}$ by solving the first-order conditions\n",
    "$$\n",
    "{\\frac {\\delta \\kappa} e} +  {\\frac d {d e}} \\left[V_x(x)  \\cdot \\int_\\Theta  \\mu_X\\left(x, i, j, a  \\mid \\theta \\right) {\\widehat q}(\\theta \\mid x ) P(d\\theta)\\right] = 0 .\n",
    "$$\n",
    "These first-order conditions turn out not to depend on $(i,j)$.\n",
    "\n",
    "\n",
    "5) use the minimization output from step (2) and  maximization output from step (4) and construct an adjusted drift using the following formula, which is the analog to formula (20) from the paper:\n",
    "\\begin{equation*}\n",
    "{\\widehat \\mu}(x) = \\int_\\Theta  \\mu_X\\left(x, {\\widehat a}  \\mid \\theta \\right) {\\widehat q}(\\theta \\mid x ) P(d\\theta) + \\sigma_X(x) {\\widehat g}(x);\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6)  construct the linear equation system for a new value function $V = {\\widehat V}$:\n",
    "\n",
    "\\begin{align*}\n",
    "0 =  & - \\delta V(x)  + \\delta (1 - \\kappa) \\left( \\log \\left[ {\\alpha}  - {\\widehat i}(x)  - {\\widehat j} (x)  \\right]\n",
    "+ k -  d   \\right) + \\delta \\kappa \\left[ \\log {\\widehat e}(x)   +  r \\right] \\cr\n",
    "& + {\\frac {\\partial V}{\\partial x}} (x) \\cdot {\\widehat \\mu}(x)\n",
    "+{\\frac 1 2} \\textrm{trace} \\left[\\sigma_X(x)' {\\frac {\\partial^2 V}{\\partial x \\partial x'}}(x) \\sigma_X(x) \\right] \\cr\n",
    "& + {\\frac {\\xi_m} 2} {\\widehat g}(x) \\cdot {\\widehat g}(x)   + \\xi_p {\\widehat {\\mathbb I}}(x);\n",
    "\\end{align*}\n",
    "\n",
    "7) modify this equation by adding a so-called \"false transient\" to the left-hand side:\n",
    "\n",
    "\\begin{align*}\n",
    "{\\frac {V(x) - {\\widetilde V}(x)} \\epsilon}  =  & - \\delta V(x)  + \\delta (1 - \\kappa) \\left( \\log \\left[ {\\alpha}  - {\\widehat i}(x)  - {\\widehat j} (x)  \\right]\n",
    "+ k -  d    \\right) + \\delta \\kappa \\left[ \\log {\\widehat e}(x)   +  r \\right] \\cr\n",
    "& + {\\frac {\\partial V}{\\partial x}} (x) \\cdot {\\widehat \\mu}(x)\n",
    "+{\\frac 1 2} \\textrm{trace} \\left[\\sigma_X(x)' {\\frac {\\partial^2 V}{\\partial x \\partial x'}}(x) \\sigma_X(x) \\right] \\cr\n",
    "& + {\\frac {\\xi_m} 2} {\\widehat g}(x) \\cdot {\\widehat g}(x)   + \\xi_p {\\widehat {\\mathbb I}}(x);\n",
    "\\end{align*}\n",
    "\n",
    "8) solve the linear system from step (7) for $V= {\\widehat V}$ using a conjugate-gradient method;\n",
    "\n",
    "9) set ${\\widetilde V} = {\\widehat V}$ and ${\\widetilde a} = {\\widehat a}$ and repeat steps (2) - (8)  until convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:07:18.290672Z",
     "start_time": "2021-03-26T14:07:18.267705Z"
    }
   },
   "outputs": [],
   "source": [
    "McD = np.loadtxt('./data/TCRE_MacDougallEtAl2017_update.txt')\n",
    "par_lambda_McD = McD / 1000\n",
    "\n",
    "Œ≤ùòß = np.mean(par_lambda_McD)  # Climate sensitivity parameter, MacDougall (2017)\n",
    "œÉ·µ¶ = np.var(par_lambda_McD, ddof = 1)  # varaiance of climate sensitivity parameters\n",
    "Œª = 1.0 / œÉ·µ¶ \n",
    "\n",
    "quadrature = 'legendre'\n",
    "n = 30\n",
    "a = Œ≤ùòß - 5 * np.sqrt(œÉ·µ¶)\n",
    "b = Œ≤ùòß + 5 * np.sqrt(œÉ·µ¶)\n",
    "\n",
    "(xs,ws) = quad_points_legendre(n)\n",
    "xs = (b-a) * 0.5  * xs + (a + b) * 0.5\n",
    "s = np.prod((b-a) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:07:44.905548Z",
     "start_time": "2021-03-26T14:07:23.544555Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "McD = np.loadtxt('./data/TCRE_MacDougallEtAl2017_update.txt')\n",
    "par_lambda_McD = McD / 1000\n",
    "\n",
    "Œ≤ùòß = np.mean(par_lambda_McD)  # Climate sensitivity parameter, MacDougall (2017)\n",
    "œÉ·µ¶ = np.var(par_lambda_McD, ddof = 1)  # varaiance of climate sensitivity parameters\n",
    "Œª = 1.0 / œÉ·µ¶ \n",
    "\n",
    "# Parameters as defined in the paper\n",
    "Œ¥ = 0.01        \n",
    "Œ∫ = 0.032       \n",
    "œÉùò® = 0.02\n",
    "œÉùò¨ = 0.0161\n",
    "œÉùò≥ = 0.0339 \n",
    "Œ± = 0.115000000000000\n",
    "œï0 = 0.0600\n",
    "œï1 = 16.666666666666668\n",
    "Œºk = -0.034977443912449\n",
    "œà0 = 0.112733407891680\n",
    "œà1 = 0.142857142857143\n",
    "\n",
    "# parameters for damage function settings\n",
    "power = 2 \n",
    "Œ≥1 = 0.00017675\n",
    "Œ≥2 = 2. * 0.0022\n",
    "Œ≥2_plus = 2. * 0.0197\n",
    "Œ≥ÃÑ2_plus = weight * 0 + (1 - weight) * Œ≥2_plus\n",
    "\n",
    "œÉ1 = 0\n",
    "œÉ2 = 0\n",
    "œÅ12 = 0\n",
    "FÃÑ = 2\n",
    "crit = 2\n",
    "F0 = 1\n",
    "\n",
    "xi_d = -1 * (1 - Œ∫)\n",
    "\n",
    "# See Remark 2.1.1 regarding the choice of Œµ and Œ∑\n",
    "# False Trasient Time step\n",
    "Œµ = 0.3\n",
    "# Cobweb learning rate\n",
    "Œ∑ = 0.05\n",
    "\n",
    "\n",
    "# Specifying Tolerance level\n",
    "tol = 1e-8\n",
    "\n",
    "# Grids Specification\n",
    "\n",
    "# Coarse Grids\n",
    "# R_min = 0\n",
    "# R_max = 9\n",
    "# F_min = 0\n",
    "# F_max = 4000\n",
    "# K_min = 0\n",
    "# K_max = 18\n",
    "# nR = 4\n",
    "# nF = 4\n",
    "# nK = 4\n",
    "# R = np.linspace(R_min, R_max, nR)\n",
    "# F = np.linspace(F_min, F_max, nF)\n",
    "# K = np.linspace(K_min, K_max, nK)\n",
    "\n",
    "# hR = R[1] - R[0]\n",
    "# hF = F[1] - F[0]\n",
    "# hK = K[1] - K[0]\n",
    "\n",
    "# Dense Grids\n",
    "\n",
    "R_min = 0\n",
    "R_max = 9\n",
    "F_min = 0\n",
    "F_max = 4000\n",
    "K_min = 0\n",
    "K_max = 18\n",
    "\n",
    "hR = 0.05\n",
    "hF = 25\n",
    "hK = 0.15\n",
    "\n",
    "R = np.arange(R_min, R_max + hR, hR)\n",
    "nR = len(R)\n",
    "F = np.arange(F_min, F_max + hF, hF)\n",
    "nF = len(F)\n",
    "K = np.arange(K_min, K_max + hK, hK)\n",
    "nK = len(K)\n",
    "\n",
    "# Discretization of the state space for numerical PDE solution. \n",
    "# See Remark 2.1.2\n",
    "(R_mat, F_mat, K_mat) = np.meshgrid(R,F,K, indexing = 'ij')\n",
    "stateSpace = np.hstack([R_mat.reshape(-1,1,order = 'F'),F_mat.reshape(-1,1,order = 'F'),K_mat.reshape(-1,1,order = 'F')])\n",
    "\n",
    "# Inputs for function quad_int\n",
    "# Integrating across parameter distribution\n",
    "quadrature = 'legendre'\n",
    "n = 30\n",
    "a = Œ≤ùòß - 5 * np.sqrt(œÉ·µ¶)\n",
    "b = Œ≤ùòß + 5 * np.sqrt(œÉ·µ¶)\n",
    "\n",
    "v0 = Œ∫ * R_mat + (1-Œ∫) * K_mat - Œ≤ùòß * F_mat\n",
    "\n",
    "FC_Err = 1\n",
    "episode = 0\n",
    "\n",
    "if smart_guess:\n",
    "    v0 = v0_guess\n",
    "    q = q_guess\n",
    "    e_star = e_guess\n",
    "    episode = 1\n",
    "    Œµ = 0.2\n",
    "    \n",
    "# while episode == 0 or FC_Err > tol:\n",
    "start_time1 = time.time()\n",
    "vold = v0.copy()\n",
    "# Applying finite difference scheme to the value function\n",
    "v0_dr = finiteDiff(v0,0,1,hR) \n",
    "v0_df = finiteDiff(v0,1,1,hF)\n",
    "v0_dk = finiteDiff(v0,2,1,hK)\n",
    "\n",
    "v0_drr = finiteDiff(v0,0,2,hR)\n",
    "v0_drr[v0_dr < 1e-16] = 0\n",
    "v0_dr[v0_dr < 1e-16] = 1e-16\n",
    "v0_dff = finiteDiff(v0,1,2,hF)\n",
    "v0_dkk = finiteDiff(v0,2,2,hK)\n",
    "if episode > 2000:\n",
    "    Œµ = 0.1\n",
    "elif episode > 1000:\n",
    "    Œµ = 0.2\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if episode == 0:\n",
    "    # First time into the loop\n",
    "    B1 = v0_dr - xi_d * (Œ≥1 + Œ≥2 * F_mat * Œ≤ùòß + Œ≥2_plus * (F_mat * Œ≤ùòß - FÃÑ) ** (power - 1) * (F_mat >= (crit / Œ≤ùòß))) * Œ≤ùòß * np.exp(R_mat) - v0_df * np.exp(R_mat)\n",
    "    C1 = - Œ¥ * Œ∫\n",
    "    e = -C1 / B1\n",
    "    e_hat = e\n",
    "    Acoeff = np.ones(R_mat.shape)\n",
    "    Bcoeff = ((Œ¥ * (1 - Œ∫) * œï1 + œï0 * œï1 * v0_dk) * Œ¥ * (1 - Œ∫) / (v0_dr * œà0 * 0.5) * np.exp(0.5 * (R_mat - K_mat))) / (Œ¥ * (1 - Œ∫) * œï1)\n",
    "    Ccoeff = -Œ±  - 1 / œï1\n",
    "    j = ((-Bcoeff + np.sqrt(Bcoeff ** 2 - 4 * Acoeff * Ccoeff)) / (2 * Acoeff)) ** 2\n",
    "    i = Œ± - j - (Œ¥ * (1 - Œ∫)) / (v0_dr * œà0 * 0.5) * j ** 0.5 * np.exp(0.5 * (R_mat - K_mat))\n",
    "    q = Œ¥ * (1 - Œ∫) / (Œ± - i - j)\n",
    "else:\n",
    "    e_hat = e_star\n",
    "\n",
    "    # Step 4 (a) : Cobeweb scheme to update controls i and j; q is an intermediary variable that determines i and j\n",
    "    Converged = 0\n",
    "    nums = 0\n",
    "    while Converged == 0:\n",
    "        i_star = (œï0 * œï1 * v0_dk / q - 1) / œï1\n",
    "        j_star = (q * np.exp(œà1 * (R_mat - K_mat)) / (v0_dr * œà0 * œà1)) ** (1 / (œà1 - 1))\n",
    "        if Œ± > np.max(i_star + j_star):\n",
    "            q_star = Œ∑ * Œ¥ * (1 - Œ∫) / (Œ± - i_star - j_star) + (1 - Œ∑) * q\n",
    "        else:\n",
    "            q_star = 2 * q\n",
    "        if np.max(abs(q - q_star) / Œ∑) <= 1e-5:\n",
    "            Converged = 1\n",
    "            q = q_star\n",
    "            i = i_star\n",
    "            j = j_star\n",
    "        else:\n",
    "            q = q_star\n",
    "            i = i_star\n",
    "            j = j_star\n",
    "\n",
    "        nums += 1\n",
    "    if episode % 100 == 0:\n",
    "        print('Cobweb Passed, iterations: {}, i error: {:10f}, j error: {:10f}'.format(nums, np.max(i - i_star), np.max(j - j_star)))\n",
    "\n",
    "a1 = np.zeros(R_mat.shape)\n",
    "b1 = xi_d * e_hat * np.exp(R_mat) * Œ≥1\n",
    "c1 = 2 * xi_d * e_hat * np.exp(R_mat) * F_mat * Œ≥2 \n",
    "ŒªÃÉ1 = Œª + c1 / Œæp\n",
    "Œ≤ÃÉ1 = Œ≤ùòß - c1 * Œ≤ùòß / (Œæp * ŒªÃÉ1) -  b1 /  (Œæp * ŒªÃÉ1)\n",
    "I1 = a1 - 0.5 * np.log(Œª) * Œæp + 0.5 * np.log(ŒªÃÉ1) * Œæp + 0.5 * Œª * Œ≤ùòß ** 2 * Œæp - 0.5 * ŒªÃÉ1 * (Œ≤ÃÉ1) ** 2 * Œæp\n",
    "R1 = 1 / Œæp * (I1 - (a1 + b1 * Œ≤ÃÉ1 + c1 / 2 * Œ≤ÃÉ1 ** 2 + c1 / 2 / ŒªÃÉ1))\n",
    "J1_without_e = xi_d * (Œ≥1 * Œ≤ÃÉ1 + Œ≥2 * F_mat * (Œ≤ÃÉ1 ** 2 + 1 / ŒªÃÉ1)) * np.exp(R_mat)\n",
    "\n",
    "œÄÃÉ1 = weight * np.exp(-1 / Œæp * I1)\n",
    "\n",
    "# Step (2), solve minimization problem in HJB and calculate drift distortion\n",
    "# See remark 2.1.3 for more details\n",
    "start_time2 = time.time()\n",
    "if episode == 0 or (smart_guess and episode == 1):\n",
    "    #@nb.jit(nopython = True, parallel = True)\n",
    "    def scale_2_fnc(x, ndist, e_hat):\n",
    "        return np.exp(-1 / Œæp * x * e_hat) * ndist\n",
    "\n",
    "    #@nb.jit(nopython = True, parallel = True)\n",
    "    def q2_tilde_fnc(x, e_hat, scale_2):\n",
    "        return np.exp(-1 / Œæp * x * e_hat) / scale_2\n",
    "\n",
    "    #@nb.jit(nopython = True, parallel = True)\n",
    "    def J2_without_e_fnc(x, ndist, e_hat, scale_2):\n",
    "        return x * q2_tilde_fnc(x, e_hat, scale_2) * ndist\n",
    "\n",
    "    (xs,ws) = quad_points_legendre(n)\n",
    "    xs = (b-a) * 0.5  * xs + (a + b) * 0.5\n",
    "    s = np.prod((b-a) * 0.5)\n",
    "\n",
    "    normdists = np.zeros(n)\n",
    "    distort_terms = np.zeros((n, nR, nF, nK))\n",
    "    for i_iter in range(n):\n",
    "        normdists[i_iter] = normpdf(xs[i_iter],Œ≤ùòß,np.sqrt(œÉ·µ¶))\n",
    "        distort_terms[i_iter] = xi_d * (Œ≥1 * xs[i_iter] + Œ≥2 * xs[i_iter] ** 2 * F_mat + Œ≥2_plus * xs[i_iter] * (xs[i_iter] * F_mat - FÃÑ) ** (power - 1) * ((xs[i_iter] * F_mat - FÃÑ) >= 0)) * np.exp(R_mat)\n",
    "\n",
    "scale_2 = np.zeros(F_mat.shape)\n",
    "for i_iter in range(n):\n",
    "    scale_2 += ws[i_iter] * scale_2_fnc(distort_terms[i_iter], normdists[i_iter], e_hat)\n",
    "scale_2 = s * scale_2\n",
    "\n",
    "I2 = -1 * Œæp * np.log(scale_2)\n",
    "\n",
    "J2_without_e = np.zeros(F_mat.shape)\n",
    "for i_iter in range(n):\n",
    "    J2_without_e += ws[i_iter] * J2_without_e_fnc(distort_terms[i_iter], normdists[i_iter], e_hat, scale_2)\n",
    "J2_without_e = s * J2_without_e\n",
    "J2_with_e = J2_without_e * e_hat\n",
    "end_time2 = time.time()\n",
    "\n",
    "\n",
    "R2 = (I2 - J2_with_e) / Œæp\n",
    "œÄÃÉ2 = (1 - weight) * np.exp(-1 / Œæp * I2)\n",
    "œÄÃÉ1_norm = œÄÃÉ1 / (œÄÃÉ1 + œÄÃÉ2)\n",
    "œÄÃÉ2_norm = 1 - œÄÃÉ1_norm\n",
    "\n",
    "# step 4 (b) updating e based on first order conditions\n",
    "expec_e_sum = (œÄÃÉ1_norm * J1_without_e + œÄÃÉ2_norm * J2_without_e)\n",
    "\n",
    "B1 = v0_dr - v0_df * np.exp(R_mat) - expec_e_sum\n",
    "C1 = -Œ¥ * Œ∫\n",
    "e = -C1 / B1\n",
    "e_star = e\n",
    "\n",
    "J1 = J1_without_e * e_star\n",
    "J2 = J2_without_e * e_star\n",
    "\n",
    "# Step (3) calculating implied entropies\n",
    "I_term = -1 * Œæp * np.log(œÄÃÉ1 + œÄÃÉ2)\n",
    "\n",
    "R1 = (I1 - J1) / Œæp\n",
    "R2 = (I2 - J2) / Œæp\n",
    "\n",
    "# Step (5) solving for adjusted drift\n",
    "drift_distort = (œÄÃÉ1_norm * J1 + œÄÃÉ2_norm * J2)\n",
    "\n",
    "if weight == 0 or weight == 1:\n",
    "    RE = œÄÃÉ1_norm * R1 + œÄÃÉ2_norm * R2\n",
    "else:\n",
    "    RE = œÄÃÉ1_norm * R1 + œÄÃÉ2_norm * R2 + œÄÃÉ1_norm * np.log(\n",
    "        œÄÃÉ1_norm / weight) + œÄÃÉ2_norm * np.log(œÄÃÉ2_norm / (1 - weight))\n",
    "\n",
    "RE_total = Œæp * RE\n",
    "\n",
    "# Step (6) and (7) Formulating HJB False Transient parameters\n",
    "# See remark 2.1.4 for more details\n",
    "A = -Œ¥ * np.ones(R_mat.shape)\n",
    "B_r = -e_star + œà0 * (j ** œà1) * np.exp(œà1 * (K_mat - R_mat)) - 0.5 * (œÉùò≥ ** 2)\n",
    "B_f = e_star * np.exp(R_mat)\n",
    "B_k = Œºk + œï0 * np.log(1 + i * œï1) - 0.5 * (œÉùò¨ ** 2)\n",
    "C_rr = 0.5 * œÉùò≥ ** 2 * np.ones(R_mat.shape)\n",
    "C_ff = np.zeros(R_mat.shape)\n",
    "\n",
    "C_kk = 0.5 * œÉùò¨ ** 2 * np.ones(R_mat.shape)\n",
    "D = Œ¥ * Œ∫ * np.log(e_star) + Œ¥ * Œ∫ * R_mat + Œ¥ * (1 - Œ∫) * (np.log(Œ± - i - j) + K_mat) + drift_distort + RE_total # + I_term \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total: 25.39 seconds; Quadrature: 7.60 seconds; Conjugate Gradient: 15.38 seconds\nEpisode 0: PDE Error: 0.2870213469; False Transient Error: 0.0824783549; Iterations: 117; CG Error: 0.0000000001\n"
     ]
    }
   ],
   "source": [
    "# Step (8) solving linear system using a conjugate-gradient method in C++\n",
    "# See remark 2.1.5, 2.1.6 for more details\n",
    "start_time3 = time.time()\n",
    "out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, v0, Œµ, solverType = 'False Transient')\n",
    "out_comp = out[2].reshape(v0.shape,order = \"F\")\n",
    "\n",
    "# Calculating PDE error and False Transient error\n",
    "PDE_rhs = A * v0 + B_r * v0_dr + B_f * v0_df + B_k * v0_dk + C_rr * v0_drr + C_kk * v0_dkk + C_ff * v0_dff + D\n",
    "PDE_Err = np.max(abs(PDE_rhs))\n",
    "FC_Err = np.max(abs((out_comp - v0)))\n",
    "print(\"Total: {:.2f} seconds; Quadrature: {:.2f} seconds; Conjugate Gradient: {:.2f} seconds\".format(time.time() - start_time1, end_time2 - start_time2, time.time() - start_time3))\n",
    "if episode % 1 == 0:\n",
    "    print(\"Episode {:d}: PDE Error: {:.10f}; False Transient Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\" .format(episode, PDE_Err, FC_Err, out[0], out[1]))\n",
    "episode += 1\n",
    "\n",
    "# step 9: keep iterating until convergence\n",
    "v0 = out_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:08:39.331252Z",
     "start_time": "2021-03-26T14:08:38.900333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming the 3-d coefficient matrix to 1-dimensional\n",
    "A = A.reshape(-1,1,order = 'F')\n",
    "B = np.hstack([B_r.reshape(-1,1,order = 'F'),B_f.reshape(-1,1,order = 'F'),B_k.reshape(-1,1,order = 'F')])\n",
    "C = np.hstack([C_rr.reshape(-1,1,order = 'F'), C_ff.reshape(-1,1,order = 'F'), C_kk.reshape(-1,1,order = 'F')])\n",
    "D = D.reshape(-1,1,order = 'F')\n",
    "v0 = v0.reshape(-1,1,order = 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:12:03.822922Z",
     "start_time": "2021-03-26T14:11:43.583012Z"
    }
   },
   "outputs": [],
   "source": [
    "# You need to uncomment line 498 in Climate/src/cppcore/src/SolveLinSys.cpp\n",
    "# which is saveMarket(linearSys_vars.Le,\"Le_local_dt.dat\");\n",
    "# then recompile the c++ code by running install.bat,  which is equivalently running pip install ./src/cppcore at the climate folder\n",
    "# ideally you will find a Le_local_dt.dat in the root folder\n",
    "out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, v0, Œµ, solverType = 'False Transient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling matrix in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:09:22.012747Z",
     "start_time": "2021-03-26T14:09:22.008758Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import spdiags\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T13:49:39.181768Z",
     "start_time": "2021-03-26T13:49:39.169797Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is to load the saved coefficient matrix in c++ \n",
    "data = np.genfromtxt('Le_local_dt.dat',\n",
    "                     skip_header=1,\n",
    "                     names=True,\n",
    "                     dtype=None,\n",
    "                     delimiter=' ')\n",
    "# this is transforming the 'c++ generated' sparse matrix to numpy array\n",
    "# note you need to change 210000, 30000, 30000_1 by checking what the first row actuall are in that .dat file\n",
    "# the first two columns are matrices indexes, the third column is data, scaled it by -Œµ to make sure it is comparable to python matrix\n",
    "A_cpp = coo_matrix((data['448'] / -Œµ, (data['64']-1, data['64_1']-1)), shape=(64, 64)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:09:42.229112Z",
     "start_time": "2021-03-26T14:09:42.170110Z"
    }
   },
   "outputs": [],
   "source": [
    "# below is generating the finite difference coefficient matrix in python\n",
    "# These parts will only need to be calculated once\n",
    "dVec = [hR, hF, hK]\n",
    "increVec = [1, nR, nR * nF]\n",
    "I_LB_R = (stateSpace[:,0] == R_min)\n",
    "I_UB_R = (stateSpace[:,0] == R_max)\n",
    "I_LB_F = (stateSpace[:,1] == F_min)\n",
    "I_UB_F = (stateSpace[:,1] == F_max)\n",
    "I_LB_K = (stateSpace[:,2] == K_min)\n",
    "I_UB_K = (stateSpace[:,2] == K_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T14:10:56.626598Z",
     "start_time": "2021-03-26T14:10:52.449470Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2d510224a707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massemble_time1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mB_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mB_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m diag_0 = (A[:,0] - 1 / Œµ\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "assemble_time1 = time.time()\n",
    "B_plus = np.maximum(B, np.zeros(B.shape))\n",
    "B_minus = np.minimum(B, np.zeros(B.shape))\n",
    "\n",
    "diag_0 = (A[:,0] - 1 / Œµ\n",
    "          + (I_LB_R * B[:,0] / -dVec[0] + I_UB_R * B[:,0] / dVec[0] - (1 - I_LB_R - I_UB_R) * (B_plus[:,0] - B_minus[:,0]) / dVec[0] + (I_LB_R * C[:,0] + I_UB_R * C[:,0] - 2 * (1 - I_LB_R - I_UB_R) * C[:,0]) / dVec[0] ** 2)\n",
    "          + (I_LB_F * B[:,1] / -dVec[1] + I_UB_F * B[:,1] / dVec[1] - (1 - I_LB_F - I_UB_F) * (B_plus[:,1] - B_minus[:,1]) / dVec[1] + (I_LB_F * C[:,1] + I_UB_F * C[:,1] - 2 * (1 - I_LB_F - I_UB_F) * C[:,1]) / dVec[1] ** 2)\n",
    "          + (I_LB_K * B[:,2] / -dVec[2] + I_UB_K * B[:,2] / dVec[2] - (1 - I_LB_K - I_UB_K) * (B_plus[:,2] - B_minus[:,2]) / dVec[2] + (I_LB_K * C[:,2] + I_UB_K * C[:,2] - 2 * (1 - I_LB_K - I_UB_K) * C[:,2]) / dVec[2] ** 2))\n",
    "diag_R = (I_LB_R * B[:,0] / dVec[0] + (1 - I_LB_R - I_UB_R) * B_plus[:,0] / dVec[0] - 2 * I_LB_R * C[:,0] / dVec[0] ** 2 + (1 - I_LB_R - I_UB_R) * C[:,0] / dVec[0] ** 2)\n",
    "diag_Rm = (I_UB_R * B[:,0] / -dVec[0] - (1 - I_LB_R - I_UB_R) * B_minus[:,0] / dVec[0] - 2 * I_UB_R * C[:,0] / dVec[0] ** 2 + (1 - I_LB_R - I_UB_R) * C[:,0] / dVec[0] ** 2)\n",
    "diag_F = (I_LB_F * B[:,1] / dVec[1] + (1 - I_LB_F - I_UB_F) * B_plus[:,1] / dVec[1] - 2 * I_LB_F * C[:,1] / dVec[1] ** 2 + (1 - I_LB_F - I_UB_F) * C[:,1] / dVec[1] ** 2)\n",
    "diag_Fm = (I_UB_F * B[:,1] / -dVec[1] - (1 - I_LB_F - I_UB_F) * B_minus[:,1] / dVec[1] - 2 * I_UB_F * C[:,1] / dVec[1] ** 2 + (1 - I_LB_F - I_UB_F) * C[:,1] / dVec[1] ** 2)\n",
    "diag_K = (I_LB_K * B[:,2] / dVec[2] + (1 - I_LB_K - I_UB_K) * B_plus[:,2] / dVec[2] - 2 * I_LB_K * C[:,2] / dVec[2] ** 2 + (1 - I_LB_K - I_UB_K) * C[:,2] / dVec[2] ** 2)\n",
    "diag_Km = (I_UB_K * B[:,2] / -dVec[2] - (1 - I_LB_K - I_UB_K) * B_minus[:,2] / dVec[2] - 2 * I_UB_K * C[:,2] / dVec[2] ** 2 + (1 - I_LB_K - I_UB_K) * C[:,2] / dVec[2] ** 2)\n",
    "diag_RR = I_LB_R * C[:,0] / dVec[0] ** 2\n",
    "diag_RRm = I_UB_R * C[:,0] / dVec[0] ** 2\n",
    "diag_FF = I_LB_F * C[:,1] / dVec[1] ** 2\n",
    "diag_FFm = I_UB_F * C[:,1] / dVec[1] ** 2\n",
    "diag_KK = I_LB_K * C[:,2] / dVec[2] ** 2\n",
    "diag_KKm = I_UB_K * C[:,2] / dVec[2] ** 2\n",
    "\n",
    "#data = np.vstack([diag_0, diag_R, diag_Rm, diag_RR, diag_RRm, diag_F, diag_Fm, diag_FF, diag_FFm, diag_K, diag_Km, diag_KK, diag_KKm])\n",
    "data = [diag_0, diag_R, diag_Rm, diag_RR, diag_RRm, diag_F, diag_Fm, diag_FF, diag_FFm, diag_K, diag_Km, diag_KK, diag_KKm]\n",
    "diags = np.array([0,-increVec[0],increVec[0],-2*increVec[0],2*increVec[0],\n",
    "                 -increVec[1],increVec[1],-2*increVec[1],2*increVec[1],\n",
    "                 -increVec[2],increVec[2],-2*increVec[2],2*increVec[2]])\n",
    "\n",
    "# the transpose of matrix A_sp is the desired A matrix\n",
    "A_sp = spdiags(data, diags, len(diag_0), len(diag_0))\n",
    "assemble_time2 = time.time()\n",
    "print(\"Assemble the matrix in python: {:.2f} seconds\".format(assemble_time2 - assemble_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T13:50:06.128371Z",
     "start_time": "2021-03-26T13:50:06.119387Z"
    }
   },
   "outputs": [],
   "source": [
    "b = -v0 / Œµ - D"
   ]
  },
  {
   "source": [
    "## Solve the system with PETSc\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_mat = csr_matrix(A_sp.T)\n",
    "petsc_mat = PETSc.Mat().createAIJ(size=csr_mat.shape, csr=(csr_mat.indptr, csr_mat.indices, csr_mat.data))\n",
    "petsc_rhs = PETSc.Vec().createWithArray(b)\n",
    "x = petsc_mat.createVecRight()\n",
    "x.set(0)\n",
    "\n",
    "# create linear solver\n",
    "ksp = PETSc.KSP()\n",
    "ksp.create(PETSc.COMM_WORLD)\n",
    "ksp.setType('cg')\n",
    "ksp.getPC().setType('none')\n",
    "ksp.setOperators(petsc_mat)\n",
    "ksp.setFromOptions()\n",
    "petsc_time1 = time.time()\n",
    "ksp.solve(petsc_rhs, x)\n",
    "petsc_time2 = time.time()\n",
    "print(\"PETSc Conjugate Gradient: {:.2f} seconds\".format(petsc_time2 - petsc_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}