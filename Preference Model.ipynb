{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary work: Importing required packages, importing parameters setting, defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import norm\n",
    "import pdb\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "from scipy.interpolate import RegularGridInterpolator, CubicSpline\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "sys.stdout.flush()\n",
    "import os\n",
    "import pickle\n",
    "import SolveLinSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def finiteDiff(data, dim, order, dlt, cap = None):  # compute the central difference derivatives for given input and dimensions\n",
    "    \"\"\"\n",
    "This function computes up to second order derivatives via finite difference scheme\n",
    "\n",
    "Input arguments are:\n",
    "Data: Function value grids which you want to compute derivatives\n",
    "dim: specify which dimension you want to compute derivatives in\n",
    "order: denotes order of the derivative\n",
    "dlt: specify the intervals of finite difference scheme\n",
    "cap: denotes whether you want to cap derivatives to some minimum values\n",
    "\n",
    "By Jiaming Wang (Jiamingwang@uchicago.edu)\n",
    "    \"\"\"\n",
    "    res = np.zeros(data.shape)\n",
    "    if order == 1:                    # first order derivatives\n",
    "        \n",
    "        if dim == 0:                  # to first dimension\n",
    "\n",
    "            res[1:-1,:,:] = (1 / (2 * dlt)) * (data[2:,:,:] - data[:-2,:,:])\n",
    "            res[-1,:,:] = (1 / dlt) * (data[-1,:,:] - data[-2,:,:])\n",
    "            res[0,:,:] = (1 / dlt) * (data[1,:,:] - data[0,:,:])\n",
    "\n",
    "        elif dim == 1:                # to second dimension\n",
    "\n",
    "            res[:,1:-1,:] = (1 / (2 * dlt)) * (data[:,2:,:] - data[:,:-2,:])\n",
    "            res[:,-1,:] = (1 / dlt) * (data[:,-1,:] - data[:,-2,:])\n",
    "            res[:,0,:] = (1 / dlt) * (data[:,1,:] - data[:,0,:])\n",
    "\n",
    "        elif dim == 2:                # to third dimension\n",
    "\n",
    "            res[:,:,1:-1] = (1 / (2 * dlt)) * (data[:,:,2:] - data[:,:,:-2])\n",
    "            res[:,:,-1] = (1 / dlt) * (data[:,:,-1] - data[:,:,-2])\n",
    "            res[:,:,0] = (1 / dlt) * (data[:,:,1] - data[:,:,0])\n",
    "\n",
    "        else:\n",
    "            raise ValueError('wrong dim')\n",
    "            \n",
    "    elif order == 2:\n",
    "        \n",
    "        if dim == 0:                  # to first dimension\n",
    "\n",
    "            res[1:-1,:,:] = (1 / dlt ** 2) * (data[2:,:,:] + data[:-2,:,:] - 2 * data[1:-1,:,:])\n",
    "            res[-1,:,:] = (1 / dlt ** 2) * (data[-1,:,:] + data[-3,:,:] - 2 * data[-2,:,:])\n",
    "            res[0,:,:] = (1 / dlt ** 2) * (data[2,:,:] + data[0,:,:] - 2 * data[1,:,:])\n",
    "\n",
    "        elif dim == 1:                # to second dimension\n",
    "\n",
    "            res[:,1:-1,:] = (1 / dlt ** 2) * (data[:,2:,:] + data[:,:-2,:] - 2 * data[:,1:-1,:])\n",
    "            res[:,-1,:] = (1 / dlt ** 2) * (data[:,-1,:] + data[:,-3,:] - 2 * data[:,-2,:])\n",
    "            res[:,0,:] = (1 / dlt ** 2) * (data[:,2,:] + data[:,0,:] - 2 * data[:,1,:])\n",
    "\n",
    "        elif dim == 2:                # to third dimension\n",
    "\n",
    "            res[:,:,1:-1] = (1 / dlt ** 2) * (data[:,:,2:] + data[:,:,:-2] - 2 * data[:,:,1:-1])\n",
    "            res[:,:,-1] = (1 / dlt ** 2) * (data[:,:,-1] + data[:,:,-3] - 2 * data[:,:,-2])\n",
    "            res[:,:,0] = (1 / dlt ** 2) * (data[:,:,2] + data[:,:,0] - 2 * data[:,:,1])\n",
    "\n",
    "        else:\n",
    "            raise ValueError('wrong dim')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('wrong order')\n",
    "        \n",
    "    if cap is not None:\n",
    "        res[res < cap] = cap\n",
    "    return res\n",
    "\n",
    "def quad_points_legendre(n):\n",
    "    u = np.sqrt(1 / (4 - 1 / np.linspace(1,n-1,n-1)**2))  # upper diag\n",
    "    [lambda0,V] = np.linalg.eig(np.diagflat(u,1) + np.diagflat(u,-1))  # V's column vectors are the main d\n",
    "    i = np.argsort(lambda0)\n",
    "    Vtop = V[0,:]\n",
    "    Vtop = Vtop[i]\n",
    "    w = 2 * Vtop ** 2\n",
    "    return (lambda0[i],w)\n",
    "\n",
    "def quad_points_hermite(n):\n",
    "    i = np.linspace(1,n-1,n-1)\n",
    "    a = np.sqrt(i / 2.0)\n",
    "    [lambda0,V] = np.linalg.eig(np.diagflat(a,1) + np.diagflat(a,-1))\n",
    "    i = np.argsort(lambda0)\n",
    "    Vtop = V[0,:]\n",
    "    Vtop = Vtop[i]\n",
    "    w = np.sqrt(np.pi) * Vtop ** 2\n",
    "    return (lambda0[i],w)\n",
    "\n",
    "\n",
    "def quad_int(f,a,b,n,method):\n",
    "    \"\"\"\n",
    "This function takes a function f to integrate from the multidimensional\n",
    "interval specified by the row vectors a and b. N different points are used\n",
    "in the quadrature method. Legendre and Hermite basis functions are\n",
    "currently supported. In the case of Hermite methodology b is the normal\n",
    "density and a is the normal mean.\n",
    "\n",
    "Created by John Wilson (johnrwilson@uchicago.edu) & Updated by Jiaming Wang (Jiamingwang@uchicago.edu)\n",
    "    \"\"\"\n",
    "    if method == 'legendre':\n",
    "        \n",
    "        (xs,ws) = quad_points_legendre(n)\n",
    "        g = lambda x: f((b-a) * 0.5  * x + (a + b) * 0.5)\n",
    "        s = np.prod((b-a) * 0.5)                \n",
    "        \n",
    "    elif method == 'hermite':\n",
    "        \n",
    "        (xs,ws) = quad_points_hermite(n)\n",
    "        g = lambda x: f(np.sqrt(2) * b * x + a)\n",
    "        s = 1 / np.sqrt(np.pi)\n",
    "        \n",
    "    else:\n",
    "        raise TypeError('Wrong polynomials specification')\n",
    "    \n",
    "    \n",
    "    tp = type(a)\n",
    "    if tp is np.float64 or tp is int or tp is np.double:\n",
    "        res = 0\n",
    "        for i in range(n):\n",
    "#             pdb.set_trace()\n",
    "            res += ws[i] * g(xs[i])\n",
    "    else:\n",
    "        raise ValueError('dimension is not 1')\n",
    "    \n",
    "    return s * res\n",
    "\n",
    "\n",
    "def cap(x, lb, ub):\n",
    "    if x <= ub or x >= lb:\n",
    "        return x\n",
    "    else:\n",
    "        if x > ub:\n",
    "            return ub\n",
    "        else:\n",
    "            return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, v0, Îµ = 1, solverType = 'False Transient'):\n",
    "\n",
    "    if solverType == 'False Transient':\n",
    "        A = A.reshape(-1,1,order = 'F')\n",
    "        B = np.hstack([B_r.reshape(-1,1,order = 'F'),B_f.reshape(-1,1,order = 'F'),B_k.reshape(-1,1,order = 'F')])\n",
    "        C = np.hstack([C_rr.reshape(-1,1,order = 'F'), C_ff.reshape(-1,1,order = 'F'), C_kk.reshape(-1,1,order = 'F')])\n",
    "        D = D.reshape(-1,1,order = 'F')\n",
    "        v0 = v0.reshape(-1,1,order = 'F')\n",
    "        v1 = v0.reshape(-1,1,order = 'F')\n",
    "        out = SolveLinSys.solveFT(stateSpace, A, B, C, D, v0, Îµ)\n",
    "\n",
    "        return out\n",
    "\n",
    "    elif solverType == 'Feyman Kac':\n",
    "        \n",
    "        A = A.reshape(-1, 1, order='F')\n",
    "        B = np.hstack([B_r.reshape(-1, 1, order='F'), B_f.reshape(-1, 1, order='F'), B_k.reshape(-1, 1, order='F')])\n",
    "        C = np.hstack([C_rr.reshape(-1, 1, order='F'), C_ff.reshape(-1, 1, order='F'), C_kk.reshape(-1, 1, order='F')])\n",
    "        D = D.reshape(-1, 1, order='F')\n",
    "        v0 = v0.reshape(-1, 1, order='F')\n",
    "        out = SolveLinSys.solveFK(stateSpace, A, B, C, D, v0)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving HJB for Preference Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = loadmat('/Users/han/Dropbox/share with John/Final Code/Preference/hjb_solution/Averse_weighted.mat')\n",
    "v0_guess = check['out_comp']\n",
    "q_guess = check['q']\n",
    "e_guess = check['e_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Damage function choics\n",
    "damageSpec = 'Weighted'  # Choose among \"High\"(Weitzman), 'Low'(Nordhaus) and 'Weighted'\n",
    "if damageSpec == 'High':\n",
    "    weight = 0.0\n",
    "elif damageSpec == 'Low':\n",
    "    weight = 1.0\n",
    "else:\n",
    "    weight = 0.5\n",
    "\n",
    "Î¾â‚š =  1 / 4000  # Ambiguity Averse Paramter \n",
    "# Sensible choices are from 0.0002 to 4000, while for parameters input over 0.01 the final results won't alter as much\n",
    "    \n",
    "McD = np.loadtxt('./data/TCRE_MacDougallEtAl2017_update.txt')\n",
    "par_lambda_McD = McD / 1000\n",
    "\n",
    "Î²ğ˜§ = np.mean(par_lambda_McD)  # Climate sensitivity parameter, MacDougall (2017)\n",
    "Ïƒáµ¦ = np.var(par_lambda_McD, ddof = 1)  # varaiance of climate sensitivity parameters\n",
    "Î» = 1.0 / Ïƒáµ¦ \n",
    "Î´ = 0.01        # subjective rate of discount\n",
    "Îº = 0.032       # \n",
    "Ïƒğ˜¨ = 0.02\n",
    "Ïƒğ˜¬ = 0.0161\n",
    "Ïƒğ˜³ = 0.0339 \n",
    "Î± = 0.115000000000000\n",
    "Ï•0 = 0.0600\n",
    "Ï•1 = 16.666666666666668\n",
    "Î¼Ì„â‚– = -0.034977443912449\n",
    "Ïˆ0 = 0.112733407891680\n",
    "Ïˆ1 = 0.142857142857143\n",
    "\n",
    "# parameters for damage function settings\n",
    "power = 2 \n",
    "Î³1 = 0.00017675\n",
    "Î³2 = 2. * 0.0022\n",
    "Î³2_plus = 2. * 0.0197\n",
    "Î³Ì„2_plus = weight * 0 + (1 - weight) * Î³2_plus\n",
    "\n",
    "Ïƒ1 = 0\n",
    "Ïƒ2 = 0\n",
    "Ï12 = 0\n",
    "FÌ„ = 2\n",
    "crit = 2\n",
    "F0 = 1\n",
    "\n",
    "## dont understand this part  maybe it's only for growth\n",
    "# Ïƒ = np.matrix([[Ïƒ1 ** 2, Ï12], [Ï12, Ïƒ2 ** 2]])\n",
    "# Î£ = np.matrix([[Ïƒáµ¦, 0, 0], \n",
    "#                    [0, Ïƒ1 ** 2, Ï12], \n",
    "#                    [0, Ï12, Ïƒ2 ** 2]])\n",
    "# dee = np.matrix([Î³1 + Î³2 * F0 + Î³2_plus * (F0 - FÌ„) ** 2 * (F0 >= 2), Î²ğ˜§, Î²ğ˜§ * F0])\n",
    "# Ïƒğ˜¥ = float(np.sqrt(dee * Î£ * dee.T))\n",
    "xi_d = -1 * (1 - Îº)\n",
    "\n",
    "# False Trasient Time step\n",
    "Îµ = 0.1\n",
    "# Specifying Tolerance level\n",
    "tol = 1e-16\n",
    "# Cobweb learning rate\n",
    "Î· = 0.05\n",
    "\n",
    "# Grids Specification\n",
    "\n",
    "# Coarse Grids\n",
    "# nR = 30\n",
    "# nF = 40\n",
    "# nK = 25\n",
    "# R = np.linspace(R_min, R_max, nR)\n",
    "# F = np.linspace(F_min, F_max, nF)\n",
    "# K = np.linspace(K_min, K_max, nK)\n",
    "\n",
    "# hR = R[1] - R[0]\n",
    "# hF = F[1] - F[0]\n",
    "# hK = K[1] - K[0]\n",
    "\n",
    "# Dense Grids\n",
    "\n",
    "R_min = 0\n",
    "R_max = 9\n",
    "F_min = 0\n",
    "F_max = 4000\n",
    "K_min = 0\n",
    "K_max = 18\n",
    "\n",
    "hR = 0.05\n",
    "hF = 25\n",
    "hK = 0.15\n",
    "\n",
    "R = np.arange(R_min, R_max + hR, hR)\n",
    "nR = len(R)\n",
    "F = np.arange(F_min, F_max + hF, hF)\n",
    "nF = len(F)\n",
    "K = np.arange(K_min, K_max + hK, hK)\n",
    "nK = len(K)\n",
    "\n",
    "(R_mat, F_mat, K_mat) = np.meshgrid(R,F,K, indexing = 'ij')\n",
    "stateSpace = np.hstack([R_mat.reshape(-1,1,order = 'F'),F_mat.reshape(-1,1,order = 'F'),K_mat.reshape(-1,1,order = 'F')])\n",
    "\n",
    "# Inputs for function quad_int; Integrating across parameter distribution\n",
    "quadrature = 'legendre'\n",
    "n = 30\n",
    "a = Î²ğ˜§ - 5 * np.sqrt(Ïƒáµ¦)\n",
    "b = Î²ğ˜§ + 5 * np.sqrt(Ïƒáµ¦)\n",
    "\n",
    "v0 = Îº * R_mat + (1-Îº) * K_mat - Î²ğ˜§ * F_mat\n",
    "\n",
    "episode = 1\n",
    "FC_Err = 1\n",
    "v0 = v0_guess\n",
    "q = q_guess\n",
    "e_star = e_guess\n",
    "\n",
    "while episode <= 1:# or FC_Err > tol:\n",
    "    vold = v0.copy()\n",
    "    # Applying finite difference scheme to the value function\n",
    "    v0_dr = finiteDiff(v0,0,1,hR) \n",
    "    v0_df = finiteDiff(v0,1,1,hF)\n",
    "    v0_dk = finiteDiff(v0,2,1,hK)\n",
    "\n",
    "    v0_drr = finiteDiff(v0,0,2,hR)\n",
    "    v0_drr[v0_dr < 1e-16] = 0\n",
    "    v0_dr[v0_dr < 1e-16] = 1e-16\n",
    "    v0_dff = finiteDiff(v0,1,2,hF)\n",
    "    v0_dkk = finiteDiff(v0,2,2,hK)\n",
    "\n",
    "    if episode == 0:\n",
    "        # First time into the loop\n",
    "        B1 = v0_dr - xi_d * (Î³1 + Î³2 * F_mat * Î²ğ˜§ + Î³2_plus * (F_mat * Î²ğ˜§ - FÌ„) ** (power - 1) * (F_mat >= (crit / Î²ğ˜§))) * Î²ğ˜§ * np.exp(R_mat) - v0_df * np.exp(R_mat)\n",
    "        C1 = - Î´ * Îº\n",
    "        e = -C1 / B1\n",
    "        e_hat = e\n",
    "#         Acoeff = np.exp(R_mat - K_mat)\n",
    "#         Bcoeff = Î´ * (1-Îº) / (np.exp(-R_mat + K_mat) * v0_dr * Ïˆ0 * 0.5) + v0_dk * Ï•0 / (np.exp(-R_mat + K_mat) * v0_dr * Ïˆ0 * 0.5)\n",
    "        Acoeff = np.ones(R_mat.shape)\n",
    "        Bcoeff = ((Î´ * (1 - Îº) * Ï•1 + Ï•0 * Ï•1 * v0_dk) * Î´ * (1 - Îº) / (v0_dr * Ïˆ0 * 0.5) * np.exp(0.5 * (R_mat - K_mat))) / (Î´ * (1 - Îº) * Ï•1)\n",
    "        Ccoeff = -Î±  - 1 / Ï•1\n",
    "        j = ((-Bcoeff + np.sqrt(Bcoeff ** 2 - 4 * Acoeff * Ccoeff)) / (2 * Acoeff)) ** 2\n",
    "#         i = (v0_dk * Ï•0 / (np.exp(-R_mat + K_mat) * v0_dr * Ïˆ0 * 0.5)) * (j ** 0.5) - 1 / Ï•1\n",
    "        i = Î± - j - (Î´ * (1 - Îº)) / (v0_dr * Ïˆ0 * 0.5) * j ** 0.5 * np.exp(0.5 * (R_mat - K_mat))\n",
    "        q = Î´ * (1 - Îº) / (Î± - i - j)\n",
    "    else:\n",
    "        e_hat = e_star\n",
    "#         j = ((Î± + 1 / Ï•1) * np.exp(-R_mat + K_mat) * (v0_dr * Ïˆ0 * Ïˆ1) / ((v0_dr * Ïˆ0 * Ïˆ1) * j ** (Ïˆ1) + (Î´ * (1-Îº) + v0_dk * Ï•0))) ** (1 / (1 - Ïˆ1))\n",
    "#         j = j * (v0_dr > 1e-8)\n",
    "#         i = ((v0_dk * Ï•0 / (np.exp(-R_mat + K_mat) * v0_dr * Ïˆ0 * Ïˆ1)) * (j ** (1 - Ïˆ1)) - 1 / Ï•1) * (v0_dr > 1e-8) + (v0_dr <= 1e-8) * (v0_dk * Ï•0 * Î± - Î´ * (1-Îº) / Ï•1) / (Î´ * (1-Îº) + v0_dk * Ï•0)\n",
    "        \n",
    "        # Cobeweb scheme to update i and j; q is \n",
    "        Converged = 0\n",
    "        nums = 0\n",
    "        while Converged == 0:\n",
    "            i_star = (Ï•0 * Ï•1 * v0_dk / q - 1) / Ï•1\n",
    "            j_star = (q * np.exp(Ïˆ1 * (R_mat - K_mat)) / (v0_dr * Ïˆ0 * Ïˆ1)) ** (1 / (Ïˆ1 - 1))\n",
    "            if Î± > np.max(i_star + j_star):\n",
    "                q_star = Î· * Î´ * (1 - Îº) / (Î± - i_star - j_star) + (1 - Î·) * q\n",
    "            else:\n",
    "                q_star = 2 * q\n",
    "            if np.max(abs(q - q_star) / Î·) <= 1e-5:\n",
    "                Converged = 1\n",
    "                q = q_star\n",
    "                i = i_star\n",
    "                j = j_star\n",
    "            else:\n",
    "                q = q_star\n",
    "                i = i_star\n",
    "                j = j_star\n",
    "            \n",
    "            nums += 1\n",
    "        print('Cobweb Passed, iterations: {}, i error: {:10f}, j error: {:10f}'.format(nums, np.max(i - i_star), np.max(j - j_star)))\n",
    "\n",
    "    a1 = np.zeros(R_mat.shape)\n",
    "    b1 = xi_d * e_hat * np.exp(R_mat) * Î³1\n",
    "    c1 = 2 * xi_d * e_hat * np.exp(R_mat) * F_mat * Î³2 \n",
    "    Î»Ìƒ1 = Î» + c1 / Î¾â‚š\n",
    "    Î²Ìƒ1 = Î²ğ˜§ - c1 * Î²ğ˜§ / (Î¾â‚š * Î»Ìƒ1) -  b1 /  (Î¾â‚š * Î»Ìƒ1)\n",
    "    I1 = a1 - 0.5 * np.log(Î») * Î¾â‚š + 0.5 * np.log(Î»Ìƒ1) * Î¾â‚š + 0.5 * Î» * Î²ğ˜§ ** 2 * Î¾â‚š - 0.5 * Î»Ìƒ1 * (Î²Ìƒ1) ** 2 * Î¾â‚š\n",
    "    #     R1 = \\xi\\_p.*(I1-(a1+b1.*Î²Ìƒ1+c1./2.*(Î²Ìƒ1).^2+c1./2./\\lambda\\tilde_1));\n",
    "    R1 = 1 / Î¾â‚š * (I1 - (a1 + b1 * Î²Ìƒ1 + c1 / 2 * Î²Ìƒ1 ** 2 + c1 / 2 / Î»Ìƒ1))\n",
    "    J1_without_e = xi_d * (Î³1 * Î²Ìƒ1 + Î³2 * F_mat * (Î²Ìƒ1 ** 2 + 1 / Î»Ìƒ1)) * np.exp(R_mat)\n",
    "\n",
    "    Ï€Ìƒ1 = weight * np.exp(-1 / Î¾â‚š * I1)\n",
    "\n",
    "    def scale_2_fnc(x):\n",
    "        return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e_hat)  * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "\n",
    "    scale_2 = quad_int(scale_2_fnc, a, b, n, 'legendre')\n",
    "\n",
    "    def q2_tilde_fnc(x):\n",
    "        return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e_hat) / scale_2\n",
    "\n",
    "    I2 = -1 * Î¾â‚š * np.log(scale_2)\n",
    "\n",
    "    def J2_without_e_fnc(x):\n",
    "        return xi_d * np.exp(R_mat) * q2_tilde_fnc(x) * (Î³1 * x + Î³2 * F_mat * x ** 2 + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "\n",
    "    J2_without_e = quad_int(J2_without_e_fnc, a, b, n, 'legendre')\n",
    "    J2_with_e = J2_without_e * e_hat\n",
    "\n",
    "    R2 = (I2 - J2_with_e) / Î¾â‚š\n",
    "    Ï€Ìƒ2 = (1 - weight) * np.exp(-1 / Î¾â‚š * I2)\n",
    "    Ï€Ìƒ1_norm = Ï€Ìƒ1 / (Ï€Ìƒ1 + Ï€Ìƒ2)\n",
    "    Ï€Ìƒ2_norm = 1 - Ï€Ìƒ1_norm\n",
    "\n",
    "    expec_e_sum = (Ï€Ìƒ1_norm * J1_without_e + Ï€Ìƒ2_norm * J2_without_e)\n",
    "\n",
    "    B1 = v0_dr - v0_df * np.exp(R_mat) - expec_e_sum\n",
    "    C1 = -Î´ * Îº\n",
    "    e = -C1 / B1\n",
    "    e_star = e\n",
    "\n",
    "    J1 = J1_without_e * e_star\n",
    "    J2 = J2_without_e * e_star\n",
    "\n",
    "    I_term = -1 * Î¾â‚š * np.log(Ï€Ìƒ1 + Ï€Ìƒ2)\n",
    "\n",
    "    R1 = (I1 - J1) / Î¾â‚š\n",
    "    R2 = (I2 - J2) / Î¾â‚š\n",
    "    drift_distort = (Ï€Ìƒ1_norm * J1 + Ï€Ìƒ2_norm * J2)\n",
    "\n",
    "    if weight == 0 or weight == 1:\n",
    "        RE = Ï€Ìƒ1_norm * R1 + Ï€Ìƒ2_norm * R2\n",
    "    else:\n",
    "        RE = Ï€Ìƒ1_norm * R1 + Ï€Ìƒ2_norm * R2 + Ï€Ìƒ1_norm * np.log(\n",
    "            Ï€Ìƒ1_norm / weight) + Ï€Ìƒ2_norm * np.log(Ï€Ìƒ2_norm / (1 - weight))\n",
    "\n",
    "    RE_total = Î¾â‚š * RE\n",
    "\n",
    "    A = -Î´ * np.ones(R_mat.shape)\n",
    "    ####\n",
    "    B_r = -e_star + Ïˆ0 * (j ** Ïˆ1) * np.exp(Ïˆ1 * (K_mat - R_mat)) - 0.5 * (Ïƒğ˜³ ** 2)\n",
    "    B_f = e_star * np.exp(R_mat)\n",
    "    B_k = Î¼Ì„â‚– + Ï•0 * np.log(1 + i * Ï•1) - 0.5 * (Ïƒğ˜¬ ** 2)\n",
    "    C_rr = 0.5 * Ïƒğ˜³ ** 2 * np.ones(R_mat.shape)\n",
    "    C_ff = np.zeros(R_mat.shape)\n",
    "    C_kk = 0.5 * Ïƒğ˜¬ ** 2 * np.ones(R_mat.shape)\n",
    "    D = Î´ * Îº * np.log(e_star) + Î´ * Îº * R_mat + Î´ * (1 - Îº) * (np.log(Î± - i - j) + K_mat) + drift_distort + RE_total # + I_term \n",
    "\n",
    "    out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, v0, Îµ, 'False Transient')\n",
    "\n",
    "    out_comp = out[2].reshape(v0.shape,order = \"F\")\n",
    "\n",
    "    PDE_rhs = A * v0 + B_r * v0_dr + B_f * v0_df + B_k * v0_dk + C_rr * v0_drr + C_kk * v0_dkk + C_ff * v0_dff + D\n",
    "    PDE_Err = np.max(abs(PDE_rhs))\n",
    "    FC_Err = np.max(abs((out_comp - v0)))\n",
    "#     if episode % 100 == 0:\n",
    "    print(\"Episode {:d}: PDE Error: {:.10f}; False Transient Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\" .format(episode, PDE_Err, FC_Err, out[0], out[1]))\n",
    "    episode += 1\n",
    "    v0 = out_comp\n",
    "\n",
    "print(\"Episode {:d}: PDE Error: {:.10f}; False Transient Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\" .format(episode, PDE_Err, FC_Err, out[0], out[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridInterp():\n",
    "\n",
    "    def __init__(self, grids, values, method = 'Linear'):\n",
    "\n",
    "        # unpacking\n",
    "        self.grids = grids\n",
    "        (self.xs, self.ys, self.zs) = grids\n",
    "        self.nx = len(self.xs)\n",
    "        self.ny = len(self.ys)\n",
    "        self.nz = len(self.zs)\n",
    "        \n",
    "        self.values = values\n",
    "\n",
    "        assert (self.nx, self.ny, self.nz) == values.shape, \"ValueError: Dimensions not match\"\n",
    "        self.method = method\n",
    "\n",
    "    def get_value(self, x, y, z):\n",
    "\n",
    "        if self.method == 'Linear':\n",
    "            \n",
    "            func = RegularGridInterpolator(self.grids, self.values)\n",
    "            return func([x,y,z])[0]\n",
    "\n",
    "        elif self.method == 'Spline':\n",
    "\n",
    "            func1 = CubicSpline(self.xs, self.values)\n",
    "            yzSpace = func1(x)\n",
    "            \n",
    "            func2 = CubicSpline(self.ys, yzSpace)\n",
    "            zSpace = func2(y)\n",
    "            \n",
    "            func3 = CubicSpline(self.zs, zSpace)\n",
    "            return func3(z)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Method Not Supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Linear'\n",
    "T = 100\n",
    "pers = 4 * T\n",
    "dt = T / pers\n",
    "nDims = 5\n",
    "its = 1\n",
    "\n",
    "gridpoints = (R, F, K)\n",
    "\n",
    "e_func_r = GridInterp(gridpoints, e, method)\n",
    "def e_func(x):\n",
    "    return e_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "j_func_r = GridInterp(gridpoints, j, method)\n",
    "def j_func(x):\n",
    "    return max(j_func_r.get_value(np.log(x[0]), x[2], np.log(x[1])), 0)\n",
    "\n",
    "i_func_r = GridInterp(gridpoints, i, method)\n",
    "def i_func(x):\n",
    "    return i_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "v_drfunc_r = GridInterp(gridpoints, v0_dr, method)\n",
    "def v_drfunc(x):\n",
    "    return v_drfunc_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "v_dtfunc_r = GridInterp(gridpoints, v0_df, method)\n",
    "def v_dtfunc(x):\n",
    "    return v_dtfunc_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "v_dkfunc_r = GridInterp(gridpoints, v0_dk, method)\n",
    "def v_dkfunc(x):\n",
    "    return v_dkfunc_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "v_func_r = GridInterp(gridpoints, v0, method)\n",
    "def v_func(x):\n",
    "    return v_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "pi_tilde_1_func_r = GridInterp(gridpoints, Ï€Ìƒ1 / (Ï€Ìƒ1 + Ï€Ìƒ2), method)\n",
    "def pi_tilde_1_func(x):\n",
    "    return pi_tilde_1_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "pi_tilde_2_func_r = GridInterp(gridpoints, Ï€Ìƒ2 / (Ï€Ìƒ1 + Ï€Ìƒ2), method)\n",
    "def pi_tilde_2_func(x):\n",
    "    return pi_tilde_2_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "def scale_2_fnc(x):\n",
    "    return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e_hat)  * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "\n",
    "scale_2 = quad_int(scale_2_fnc, a, b, n, 'legendre')\n",
    "\n",
    "def q2_tilde_fnc(x):\n",
    "    return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e_hat) / scale_2\n",
    "### keyi\n",
    "def base_model_drift_func(x):\n",
    "    return np.exp(R_mat) * e * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³Ì„2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "base_model_drift =  quad_int(base_model_drift_func, a, b, n, 'legendre')\n",
    "\n",
    "mean_nordhaus = Î²Ìƒ1\n",
    "lambda_tilde_nordhaus = Î»Ìƒ1\n",
    "nordhaus_model_drift = (Î³1 * mean_nordhaus + Î³2 * (1 / lambda_tilde_nordhaus + mean_nordhaus ** 2) * F_mat) * np.exp(R_mat) * e\n",
    "### keyi\n",
    "def weitzman_model_drift_func(x):\n",
    "    return np.exp(R_mat) * e * q2_tilde_fnc(x) * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„ ) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "weitzman_model_drift = quad_int(weitzman_model_drift_func, a, b, n, 'legendre')\n",
    "\n",
    "nordhaus_drift_func_r = GridInterp(gridpoints, nordhaus_model_drift, method)\n",
    "def nordhaus_drift_func(x):\n",
    "    return nordhaus_drift_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "weitzman_drift_func_r = GridInterp(gridpoints, weitzman_model_drift, method)\n",
    "def weitzman_drift_func(x):\n",
    "    return weitzman_drift_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "base_drift_func_r = GridInterp(gridpoints, base_model_drift, method)\n",
    "def base_drift_func (x): \n",
    "    return base_drift_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "# function handles\n",
    "####\n",
    "def muR(x):\n",
    "    return -e_func(x) + Ïˆ0 * (j_func(x) * x[1] / x[0]) ** Ïˆ1\n",
    "def muK(x): \n",
    "    return (Î¼Ì„k + Ï•0 * np.log(1 + i_func(x) * Ï•1))\n",
    "def muF(x):\n",
    "    return e_func(x) * x[0]\n",
    "def muD_base(x):\n",
    "    return base_drift_func(x)\n",
    "def muD_tilted(x):\n",
    "    return pi_tilde_1_func(x) * nordhaus_drift_func(x) + (1 - pi_tilde_1_func(x)) * weitzman_drift_func(x)\n",
    "\n",
    "def sigmaR(x):\n",
    "    return np.zeros(x[:5].shape)\n",
    "def sigmaK(x):\n",
    "    return np.zeros(x[:5].shape)\n",
    "def sigmaF(x):\n",
    "    return np.zeros(x[:5].shape)\n",
    "def sigmaD(x):\n",
    "    return np.zeros(x[:5].shape)\n",
    "\n",
    "# initial points\n",
    "R_0 = 650\n",
    "K_0 = 80 / Î±\n",
    "F_0 = 870 - 580\n",
    "initial_val = np.array([R_0, K_0, F_0])\n",
    "D_0_base = muD_base(initial_val)\n",
    "D_0_tilted = muD_tilted(initial_val)\n",
    "\n",
    "# Set bounds\n",
    "R_max_sim = np.exp(max(R))\n",
    "K_max_sim = np.exp(max(K))\n",
    "F_max_sim = max(F)\n",
    "D_max_sim = 5.0\n",
    "\n",
    "R_min_sim = np.exp(min(R))\n",
    "K_min_sim = np.exp(min(K))\n",
    "F_min_sim = min(F)\n",
    "D_min_sim = -5\n",
    "\n",
    "upperbounds = np.array([R_max_sim, K_max_sim, F_max_sim, D_max_sim, D_max_sim])\n",
    "lowerbounds = np.array([R_min_sim, K_min_sim, F_min_sim, D_min_sim, D_min_sim])\n",
    "\n",
    "hists = np.zeros([pers, nDims, its])\n",
    "# hists = hists.copy()\n",
    "e_hists = np.zeros([pers,its])\n",
    "# e_hists = e_hists.copy()\n",
    "j_hists = np.zeros([pers,its])\n",
    "# j_hists = j_hists.copy()\n",
    "i_hists = np.zeros([pers,its])\n",
    "# i_hists = i_hists.copy()\n",
    "\n",
    "v_dr_hists = np.zeros([pers,its])\n",
    "v_dt_hists = np.zeros([pers,its])\n",
    "v_dk_hists = np.zeros([pers,its])\n",
    "v_hists = np.zeros([pers,its])\n",
    "\n",
    "for iters in range(0,its):\n",
    "    hist = np.zeros([pers,nDims])\n",
    "    e_hist = np.zeros([pers,1])\n",
    "    i_hist = np.zeros([pers,1])\n",
    "    j_hist = np.zeros([pers,1])\n",
    "\n",
    "    v_dr_hist = np.zeros([pers,1])\n",
    "    v_dt_hist = np.zeros([pers,1])\n",
    "    v_dk_hist = np.zeros([pers,1])\n",
    "    v_hist = np.zeros([pers,1])\n",
    "\n",
    "    hist[0,:] = [R_0, K_0, F_0, D_0_base, D_0_tilted]\n",
    "    e_hist[0] = e_func(hist[0,:]) * hist[0,0]\n",
    "    i_hist[0] = i_func(hist[0,:]) * hist[0,1]\n",
    "    j_hist[0] = j_func(hist[0,:]) * hist[0,0]\n",
    "    v_dr_hist[0] = v_drfunc(hist[0,:])\n",
    "    v_dt_hist[0] = v_dtfunc(hist[0,:])\n",
    "    v_dk_hist[0] = v_dkfunc(hist[0,:])\n",
    "    v_hist[0] = v_func(hist[0,:])\n",
    "\n",
    "    for tm in range(1,pers):\n",
    "        shock = norm.rvs(0,np.sqrt(dt),nDims)\n",
    "        # print(muR(hist[tm-1,:]))\n",
    "        hist[tm,0] = cap(hist[tm-1,0] * np.exp((muR(hist[tm-1,:])- 0.5 * sum((sigmaR(hist[tm-1,:])) ** 2))* dt + sigmaR(hist[tm-1,:]).dot(shock)),lowerbounds[0], upperbounds[0])\n",
    "        hist[tm,1] = cap(hist[tm-1,1] * np.exp((muK(hist[tm-1,:])- 0.5 * sum((sigmaK(hist[tm-1,:])) ** 2))* dt + sigmaK(hist[tm-1,:]).dot(shock)),lowerbounds[1], upperbounds[1])\n",
    "        hist[tm,2] = cap(hist[tm-1,2] + muF(hist[tm-1,:]) * dt + sigmaF(hist[tm-1,:]).dot(shock), lowerbounds[2], upperbounds[2])\n",
    "        hist[tm,3] = cap(hist[tm-1,3] + muD_base(hist[tm-1,:]) * dt + sigmaD(hist[tm-1,:]).dot(shock), lowerbounds[3], upperbounds[3])\n",
    "        hist[tm,4] = cap(hist[tm-1,4] + muD_tilted(hist[tm-1,:]) * dt + sigmaD(hist[tm-1,:]).dot(shock), lowerbounds[4], upperbounds[4])\n",
    "\n",
    "        e_hist[tm] = e_func(hist[tm-1,:]) * hist[tm-1,0]\n",
    "        i_hist[tm] = i_func(hist[tm-1,:]) * hist[tm-1,1]\n",
    "        j_hist[tm] = j_func(hist[tm-1,:]) * hist[tm-1,0]\n",
    "\n",
    "        v_dr_hist[tm] = v_drfunc(hist[tm-1,:])\n",
    "        v_dt_hist[tm] = v_dtfunc(hist[tm-1,:])\n",
    "        v_dk_hist[tm] = v_dkfunc(hist[tm-1,:])\n",
    "        v_hist[tm] = v_func(hist[tm-1,:])\n",
    "\n",
    "    hists[:,:,iters] = hist\n",
    "    e_hists[:,[iters]] = e_hist\n",
    "    i_hists[:,[iters]] = i_hist\n",
    "    j_hists[:,[iters]] = j_hist\n",
    "\n",
    "    v_dr_hists[:,[iters]] = v_dr_hist\n",
    "    v_dt_hists[:,[iters]] = v_dt_hist\n",
    "    v_dk_hists[:,[iters]] = v_dk_hist\n",
    "    v_hists[:,[iters]] = v_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCC Calculation Feyman Kac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ = loadmat(r'C:\\Users\\jiamingwang\\Dropbox\\share with John\\Final Code\\Preference\\SCC_solution\\SCC_base_averse_weighted.mat')\n",
    "base_guess = base_['v0']\n",
    "worst_ = loadmat(r'C:\\Users\\jiamingwang\\Dropbox\\share with John\\Final Code\\Preference\\SCC_solution\\SCC_worst_averse_weighted.mat')\n",
    "worst_guess = worst_['v0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Î¾â‚š > 100:  # We consider for Î¾â‚š level over 100 as \n",
    "\n",
    "    MC = Î´ * (1-Îº) / (Î± * np.exp(K_mat) - i * np.exp(K_mat) - j * np.exp(R_mat))\n",
    "    ME = Î´ * Îº / (e * np.exp(R_mat))\n",
    "    SCC = 1000 * ME / MC\n",
    "    SCC_func_r = GridInterp(gridpoints, SCC, method)\n",
    "    \n",
    "    def SCC_func(x): \n",
    "        return SCC_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "    \n",
    "    SCC_values = np.zeros([pers,its])\n",
    "    for tm in range(pers):\n",
    "        for path in range(its):   # path is its?\n",
    "            SCC_values[tm, path] = SCC_func(hists[tm,:,path])\n",
    "\n",
    "    SCC_total = np.mean(SCC_values,axis = 1)\n",
    "\n",
    "    SCCs['SCC'] = SCC_total\n",
    "    \n",
    "else:\n",
    "\n",
    "    # Base model\n",
    "    def base_model_flow_func(x):\n",
    "        return (Î³2 * x ** 2 + Î³Ì„2_plus * x ** 2 * ((x * F_mat - FÌ„) >=0)) * np.exp(R_mat) * e *  norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "    base_model_flow = quad_int(base_model_flow_func, a, b, n, 'legendre')\n",
    "    flow_base = base_model_flow\n",
    "\n",
    "    # input for solver\n",
    "\n",
    "    A = -Î´ * np.ones(R_mat.shape)\n",
    "    ####\n",
    "    B_r = -e + Ïˆ0 * (j ** Ïˆ1) * np.exp(Ïˆ1 * (K_mat - R_mat)) - 0.5 * (Ïƒğ˜³ ** 2)\n",
    "    B_k = Î¼Ì„â‚– + Ï•0 * np.log(1 + i * Ï•1) - 0.5 * (Ïƒğ˜¬ ** 2)\n",
    "    B_f = e * np.exp(R_mat)\n",
    "    C_rr = 0.5 * Ïƒğ˜³ ** 2 * np.ones(R_mat.shape)\n",
    "    C_kk = 0.5 * Ïƒğ˜¬ ** 2 * np.ones(R_mat.shape)\n",
    "    C_ff = np.zeros(R_mat.shape)\n",
    "    D = flow_base\n",
    "\n",
    "    out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, base_guess, solverType='Feyman Kac')\n",
    "    v0_base = out[2].reshape(v0.shape, order=\"F\")\n",
    "    v0_base = v0_base\n",
    "\n",
    "    v0_dr_base = finiteDiff(v0_base,0,1,hR) \n",
    "    v0_df_base = finiteDiff(v0_base,1,1,hF)\n",
    "    v0_dk_base = finiteDiff(v0_base,2,1,hK)\n",
    "\n",
    "    v0_drr_base = finiteDiff(v0_base,0,2,hR)\n",
    "    v0_dff_base = finiteDiff(v0_base,1,2,hF)\n",
    "    v0_dkk_base = finiteDiff(v0_base,2,2,hK)\n",
    "\n",
    "    v0_drr_base[v0_dr_base < 1e-16] = 0\n",
    "    v0_dr_base[v0_dr_base < 1e-16] = 1e-16\n",
    "\n",
    "    PDE_rhs = A * v0_base + B_r * v0_dr_base + B_f * v0_df_base + B_k * v0_dk_base + C_rr * v0_drr_base + C_kk * v0_dkk_base + C_ff * v0_dff_base + D\n",
    "    PDE_Err = np.max(abs(PDE_rhs))\n",
    "    print(\"Feyman Kac Base Model Solved. PDE Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\".format(PDE_Err, out[0], out[1]))\n",
    "\n",
    "    # Worst Model\n",
    "    mean_nordhaus = Î²Ìƒ1\n",
    "    lambda_tilde_nordhaus = Î»Ìƒ1\n",
    "    def scale_2_fnc(x):\n",
    "        return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e)  * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "\n",
    "    scale_2 = quad_int(scale_2_fnc, a, b, n, 'legendre')\n",
    "\n",
    "    def q2_tilde_fnc(x):\n",
    "        return np.exp(-1 / Î¾â‚š * xi_d * (Î³1 * x + Î³2 * x ** 2 * F_mat + Î³2_plus * x * (x * F_mat - FÌ„) ** (power - 1) * ((x * F_mat - FÌ„) >= 0)) * np.exp(R_mat) * e) / scale_2\n",
    "\n",
    "    nordhaus_model_flow = (Î³2 * (1 / lambda_tilde_nordhaus + mean_nordhaus ** 2)) * np.exp(R_mat) * e \n",
    "    # weitzman_model_flow_func = @(x) q2_tilde_1_fnc(x) .*(gamma_2.*x.^2 +gamma_2_plus.*x.^2.*((x.*t_mat-f_bar)>=0)).*exp(r_mat).*e .*normpdf(x,beta_f,sqrt(var_beta_f));\n",
    "    def weitzman_model_flow_func(x): \n",
    "        return q2_tilde_fnc(x) * (Î³2 * x ** 2 + Î³2_plus * x ** 2 * ((x * F_mat - FÌ„) >= 0 )) * np.exp(R_mat) * e * norm.pdf(x,Î²ğ˜§,np.sqrt(Ïƒáµ¦))\n",
    "    weitzman_model_flow = quad_int(weitzman_model_flow_func, a, b, n, 'legendre')\n",
    "\n",
    "    I1 = a1 - 0.5 * np.log(Î») * Î¾â‚š + 0.5 * np.log(Î»Ìƒ1) * Î¾â‚š + 0.5 * Î» * Î²ğ˜§ ** 2 * Î¾â‚š - 0.5 * Î»Ìƒ1 * (Î²Ìƒ1) ** 2 * Î¾â‚š\n",
    "    I2 = -1 * Î¾â‚š * np.log(scale_2)\n",
    "    Ï€Ìƒ1 = (weight) * np.exp(-1 / Î¾â‚š * I1)\n",
    "    Ï€Ìƒ2 = (1 - weight) * np.exp(-1 / Î¾â‚š * I2)\n",
    "    Ï€Ìƒ1_norm = Ï€Ìƒ1 / (Ï€Ìƒ1 + Ï€Ìƒ2)\n",
    "    Ï€Ìƒ2_norm = 1 - Ï€Ìƒ1_norm\n",
    "\n",
    "    flow_tilted = Ï€Ìƒ1_norm * nordhaus_model_flow + Ï€Ìƒ2_norm * weitzman_model_flow\n",
    "\n",
    "    A = -Î´ * np.ones(R_mat.shape)\n",
    "    ####\n",
    "    B_r = -e + Ïˆ0 * (j ** Ïˆ1) * np.exp(Ïˆ1 * (K_mat - R_mat)) - 0.5 * (Ïƒğ˜³ ** 2)\n",
    "    B_k = Î¼Ì„â‚– + Ï•0 * np.log(1 + i * Ï•1) - 0.5 * (Ïƒğ˜¬ ** 2)\n",
    "    B_f = e * np.exp(R_mat)\n",
    "    C_rr = 0.5 * Ïƒğ˜³ ** 2 * np.ones(R_mat.shape)\n",
    "    C_kk = 0.5 * Ïƒğ˜¬ ** 2 * np.ones(R_mat.shape)\n",
    "    C_ff = np.zeros(R_mat.shape)\n",
    "    D = flow_tilted\n",
    "\n",
    "    out = PDESolver(stateSpace, A, B_r, B_f, B_k, C_rr, C_ff, C_kk, D, worst_guess, solverType='Feyman Kac')\n",
    "    v0_worst = out[2].reshape(v0.shape, order=\"F\")\n",
    "    v0_worst = v0_worst\n",
    "\n",
    "    v0_dr_worst = finiteDiff(v0_worst,0,1,hR) \n",
    "    v0_df_worst = finiteDiff(v0_worst,1,1,hF)\n",
    "    v0_dk_worst = finiteDiff(v0_worst,2,1,hK)\n",
    "\n",
    "    v0_drr_worst = finiteDiff(v0_worst,0,2,hR)\n",
    "    v0_dff_worst = finiteDiff(v0_worst,1,2,hF)\n",
    "    v0_dkk_worst = finiteDiff(v0_worst,2,2,hK)\n",
    "    v0_drr_worst[v0_dr_worst < 1e-16] = 0\n",
    "    v0_dr_worst[v0_dr_worst < 1e-16] = 1e-16\n",
    "\n",
    "    PDE_rhs = A * v0_worst + B_r * v0_dr_worst + B_f * v0_df_worst + B_k * v0_dk_worst + C_rr * v0_drr_worst + C_kk * v0_dkk_worst + C_ff * v0_dff_worst + D\n",
    "    PDE_Err = np.max(abs(PDE_rhs))\n",
    "    print(\"Feyman Kac Worst Model Solved. PDE Error: {:.10f}; Iterations: {:d}; CG Error: {:.10f}\".format(PDE_Err, out[0], out[1]))\n",
    "\n",
    "\n",
    "    # SCC decomposition\n",
    "\n",
    "    v0_dr = finiteDiff(v0,0,1,hR) \n",
    "    v0_df = finiteDiff(v0,1,1,hF)\n",
    "    v0_dk = finiteDiff(v0,2,1,hK)\n",
    "\n",
    "    v0_drr = finiteDiff(v0,0,2,hR)\n",
    "    v0_dff = finiteDiff(v0,1,2,hF)\n",
    "    v0_dkk = finiteDiff(v0,2,2,hK)\n",
    "\n",
    "    v0_drr[v0_dr < 1e-16] = 0\n",
    "    v0_dr[v0_dr < 1e-16] = 1e-16\n",
    "\n",
    "    gridpoints = (R, F, K)  # can modify\n",
    "\n",
    "    MC = Î´ * (1-Îº) / (Î± * np.exp(K_mat) - i * np.exp(K_mat) - j * np.exp(R_mat))\n",
    "    ME = Î´ * Îº / (e * np.exp(R_mat))\n",
    "    SCC = 1000 * ME / MC\n",
    "    SCC_func_r = GridInterp(gridpoints, SCC, method)\n",
    "\n",
    "    def SCC_func(x): \n",
    "        return SCC_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "    ME1 = v0_dr * np.exp(-R_mat)\n",
    "    SCC1 = 1000 * ME1 / MC\n",
    "    SCC1_func_r = GridInterp(gridpoints, SCC1, method)\n",
    "    def SCC1_func(x):\n",
    "        return SCC1_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "    ME2_base = (1-Îº) * v0_base\n",
    "    SCC2_base = 1000 * ME2_base / MC\n",
    "    SCC2_base_func_r = GridInterp(gridpoints, SCC2_base, method)\n",
    "    def SCC2_base_func(x):\n",
    "        return SCC2_base_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "    def V_d_baseline_func(x):\n",
    "        return xi_d * (Î³1 * x + Î³2 * F_mat * x** 2 +\n",
    "                        Î³Ì„2_plus * x * (x * F_mat - FÌ„) * (power - 1)\n",
    "                        * ((x * F_mat - FÌ„) >= 0 )) * norm.pdf(x, Î²ğ˜§, np.sqrt(Ïƒáµ¦))\n",
    "    V_d_baseline = quad_int(V_d_baseline_func, a, b, n, 'legendre')\n",
    "    ME2b = -V_d_baseline\n",
    "    SCC2_V_d_baseline = 1000 * ME2b / MC\n",
    "    SCC2_V_d_baseline_func_r = GridInterp(gridpoints, SCC2_V_d_baseline, method)\n",
    "    def SCC2_V_d_baseline_func(x):\n",
    "        return SCC2_V_d_baseline_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "    ME2_tilt = (1-Îº) * v0_worst\n",
    "    SCC2_tilt = 1000 * ME2_tilt / MC\n",
    "    SCC2_tilt_func_r = GridInterp(gridpoints, SCC2_tilt, method)\n",
    "    def SCC2_tilt_func(x):\n",
    "        return SCC2_tilt_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "\n",
    "    ME2b = -expec_e_sum * np.exp(-R_mat)\n",
    "    SCC2_V_d_tilt_ = 1000 * ME2b / MC\n",
    "    SCC2_V_d_tilt_func_r = GridInterp(gridpoints, SCC2_V_d_tilt_, method)\n",
    "    def SCC2_V_d_tilt_func(x):\n",
    "        return SCC2_V_d_tilt_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "\n",
    "    SCC_values = np.zeros([pers,its])\n",
    "    SCC1_values = np.zeros([pers,its])\n",
    "    SCC2_base_values = np.zeros([pers,its])\n",
    "    SCC2_tilt_values = np.zeros([pers,its])\n",
    "    SCC2_V_d_baseline_values = np.zeros([pers,its])\n",
    "    SCC2_V_d_tilt_values = np.zeros([pers,its])\n",
    "\n",
    "    for tm in range(pers):\n",
    "        for path in range(its):   # path is its?\n",
    "            SCC_values[tm, path] = SCC_func(hists[tm,:,path])\n",
    "            SCC1_values[tm, path] = SCC1_func(hists[tm,:,path])\n",
    "            SCC2_base_values[tm, path] = SCC2_base_func(hists[tm,:,path]) \n",
    "            SCC2_tilt_values[tm, path] = SCC2_tilt_func(hists[tm,:,path])\n",
    "            SCC2_V_d_baseline_values[tm, path] = SCC2_V_d_baseline_func(hists[tm,:,path])\n",
    "            SCC2_V_d_tilt_values[tm, path] = SCC2_V_d_tilt_func(hists[tm,:,path])\n",
    "\n",
    "    SCC_total = np.mean(SCC_values,axis = 1)\n",
    "    SCC_private = np.mean(SCC1_values,axis = 1)\n",
    "    SCC2_FK_base = np.mean(SCC2_base_values,axis = 1)\n",
    "    SCC2_FK_tilt = np.mean(SCC2_tilt_values,axis = 1)\n",
    "    SCC2_V_d_baseline = np.mean(SCC2_V_d_baseline_values,axis = 1)\n",
    "    SCC2_V_d_tilt = np.mean(SCC2_V_d_tilt_values,axis = 1)\n",
    "\n",
    "    SCCs = {}\n",
    "    SCCs['SCC'] = SCC_total\n",
    "    SCCs['SCC1'] = SCC_private\n",
    "    SCCs['SCC2'] = SCC2_FK_base + SCC2_V_d_baseline\n",
    "    SCCs['SCC3'] = SCC2_V_d_tilt - SCC2_V_d_baseline + SCC2_FK_tilt - SCC2_FK_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCCs['SCC3'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REs = {}\n",
    "Dists = {}\n",
    "a = Î²ğ˜§ - 5 * np.sqrt(Ïƒáµ¦)\n",
    "b = Î²ğ˜§ + 5 * np.sqrt(Ïƒáµ¦)\n",
    "a_10std = Î²ğ˜§ - 10 * np.sqrt(Ïƒáµ¦)\n",
    "b_10std = Î²ğ˜§ + 10 * np.sqrt(Ïƒáµ¦)\n",
    "\n",
    "RE_func_r = GridInterp(gridpoints, RE, method)\n",
    "def RE_func(x):\n",
    "    return RE_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "e_func_r = GridInterp(gridpoints, e, method)\n",
    "def e_func(x):\n",
    "    return e_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "pi_tilde_1_func_r = GridInterp(gridpoints, Ï€Ìƒ1, method)\n",
    "def pi_tilde_1_func(x):\n",
    "    return pi_tilde_1_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "lambda_tilde_1_func_r = GridInterp(gridpoints, Î»Ìƒ1, method)\n",
    "def lambda_tilde_1_func(x):\n",
    "    return lambda_tilde_1_func_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "beta_tilde_1_r = GridInterp(gridpoints, Î²Ìƒ1, method)\n",
    "def beta_tilde_1_func(x):\n",
    "    return beta_tilde_1_r.get_value(np.log(x[0]), x[2], np.log(x[1]))\n",
    "\n",
    "RE_plot = np.zeros(pers)\n",
    "weight_plot = np.zeros(pers)\n",
    "beta_f_space = np.linspace(a_10std,b_10std,200)\n",
    "\n",
    "#Relative Entropy\n",
    "\n",
    "if damageSpec == 'low':\n",
    "    nordhaus_mean = np.zeros(pers)\n",
    "    nordhaus_std = np.zeros(pers)\n",
    "\n",
    "    for tm in range(pers):\n",
    "        RE_plot[tm] = RE_func(hists[tm,:,0])\n",
    "        weight_plot[tm] = pi_tilde_1_func(hists[tm,:,0])\n",
    "        nordhaus_mean[tm] = beta_tilde_1_func(hists[tm,:,0])\n",
    "        nordhaus_std[tm] = 1 / np.sqrt(lambda_tilde_1_func(hists[tm,:,0]))\n",
    "\n",
    "    REs['RE'] = RE_plot\n",
    "    REs['Weights'] = weight_plot\n",
    "    REs['Shifted Mean'] = nordhaus_mean\n",
    "    REs['Shifted Std'] = nordhaus_std\n",
    "\n",
    "else:\n",
    "    for tm in range(pers):\n",
    "        RE_plot[tm] = RE_func(hists[tm,:,0])\n",
    "        weight_plot[tm] = pi_tilde_1_func(hists[tm,:,0])\n",
    "\n",
    "    REs['RE'] = RE_plot\n",
    "    REs['Weights'] = weight_plot\n",
    "\n",
    "\n",
    "original_dist = norm.pdf(beta_f_space, Î²ğ˜§, np.sqrt(Ïƒáµ¦))\n",
    "Dists['Original'] = original_dist\n",
    "    \n",
    "# probabilities (R,K,F)\n",
    "\n",
    "for tm in [1,100,200,300,400]:\n",
    "    R0 = hists[tm-1,0,0]\n",
    "    K0 = hists[tm-1,1,0]\n",
    "    F0 = hists[tm-1,2,0]\n",
    "\n",
    "    # Weitzman\n",
    "    def scale_2_fnc_prob(x):\n",
    "        return np.exp(-1 / Î¾p * xi_d * (Î³1 * x + Î³2 * x ** 2 *  F0 + Î³2_plus * x * (x * F0 - FÌ„) ** (power - 1) * ((x * F0 - FÌ„) >= 0)) * R0 * e_func([R0, K0, F0])) * norm.pdf(x, Î²ğ˜§, np.sqrt(Ïƒáµ¦))\n",
    "    scale_2_prob = quad_int(scale_2_fnc_prob, a, b, n, 'legendre')\n",
    "\n",
    "    q2_tilde_fnc_prob = np.exp(-1 / Î¾p * xi_d * (Î³1 * beta_f_space + Î³2 * beta_f_space ** 2 * F0 + Î³2_plus * beta_f_space * (beta_f_space * F0 - FÌ„) ** (power - 1) * ((beta_f_space * F0 - FÌ„) >= 0)) * R0* e_func([R0, K0, F0])) / scale_2_prob * norm.pdf(beta_f_space, Î²ğ˜§, np.sqrt(Ïƒáµ¦))\n",
    "    weitzman = q2_tilde_fnc_prob\n",
    "\n",
    "    # Nordhaus\n",
    "    mean_distort_nordhaus = beta_tilde_1_func([R0, K0, F0]) - Î²ğ˜§\n",
    "    lambda_tilde_nordhaus = lambda_tilde_1_func([R0, K0, F0])\n",
    "    nordhaus = norm.pdf(beta_f_space, mean_distort_nordhaus + Î²ğ˜§, 1 / np.sqrt(lambda_tilde_nordhaus))\n",
    "\n",
    "    # weights\n",
    "    Dists_weight = pi_tilde_1_func([R0, K0, F0])\n",
    "    if damageSpec == 'High':\n",
    "        Dists['Weitzman_year' + str(int((tm) / 4))] = weitzman\n",
    "    elif damageSpec == 'Low':\n",
    "        Dists['Nordhaus_year' + str(int((tm) / 4))] = nordhaus\n",
    "    elif damageSpec == 'Weighted':\n",
    "        Dists['Weitzman_year' + str(int((tm) / 4))] = weitzman\n",
    "        Dists['Nordhaus_year' + str(int((tm) / 4))] = nordhaus\n",
    "        Dists['Weighted_year' + str(int((tm) / 4))] = nordhaus * Dists_weight + weitzman * (1 - Dists_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as smart guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_ = loadmat(r'C:\\Users\\jiamingwang\\Dropbox\\share with John\\Final Code\\Preference\\SCC_solution\\SCC_base_neutral_weighted.mat')\n",
    "# base_guess = base_['v0']\n",
    "# worst_ = loadmat(r'C:\\Users\\jiamingwang\\Dropbox\\share with John\\Final Code\\Preference\\SCC_solution\\SCC_worst_neutral_weighted.mat')\n",
    "# worst_guess = worst_['v0']\n",
    "check = loadmat(r'C:\\Users\\jiamingwang\\Dropbox\\share with John\\Final Code\\Preference\\hjb_solution\\Neutral_high.mat')\n",
    "\n",
    "v0_guess = check['out_comp']\n",
    "q_guess = check['q']\n",
    "e_guess = check['e_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smart_guess = {}\n",
    "# prelin_results = {}\n",
    "key = 'HighNeutral'\n",
    "smart_guess[key] = {}\n",
    "smart_guess[key]['v0'] = v0_guess\n",
    "smart_guess[key]['q'] = q_guess\n",
    "smart_guess[key]['e'] = e_guess\n",
    "smart_guess[key]['base'] = None\n",
    "smart_guess[key]['worst'] = None\n",
    "\n",
    "# smart_guess['WeightedNeutral'] = {}\n",
    "# smart_guess['WeightedNeutral']['v0'] = v0_guess\n",
    "# smart_guess['WeightedNeutral']['q'] = q_guess\n",
    "# smart_guess['WeightedNeutral']['e'] = e_guess\n",
    "# smart_guess['WeightedNeutral']['base'] = base_guess\n",
    "# smart_guess['WeightedNeutral']['worst'] = worst_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_guess.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/smartguesses.pickle', \"wb\") as file_:\n",
    "    pickle.dump(smart_guess, file_, -1)\n",
    "    \n",
    "# m1 = pickle.load(open('./data/comppref.pickle', \"rb\", -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open('./data/smartguesses.pickle', \"rb\", -1))['WeightedAverse'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densityPlot(key = 'Weighted'):\n",
    "    years = [50, 75, 100]\n",
    "\n",
    "    titles = [\"Year {}\".format(year) for year in years]\n",
    "\n",
    "    fig = make_subplots(1, len(years), print_grid = False, subplot_titles = titles)\n",
    "\n",
    "    dom =beta_f_space\n",
    "    inds = ((dom>=0) & (dom<=5e-3))\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        # data = loadmat(\"{}/50-50 weight/Dist_{}yr.mat\".format(quad_rule, year))\n",
    "        data = Dists\n",
    "        if key == 'Weighted': \n",
    "            if i == 0:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = True, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Nordhaus_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'Low Damage Function', line = dict(color = 'red', dash='dashdot', width = 3), showlegend = True, legendgroup = 'Low Damage Function')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Weitzman_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'High Damage Function', line = dict(color = 'green', dash='dash', width = 3), showlegend = True, legendgroup = 'High Damage Function')\n",
    "            else:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = False, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Nordhaus_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'Low Damage Function', line = dict(color = 'red', dash='dashdot', width = 3), showlegend = False, legendgroup = 'Low Damage Function')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Weitzman_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'High Damage Function', line = dict(color = 'green', dash='dash', width = 3), showlegend = False, legendgroup = 'High Damage Function')\n",
    "\n",
    "        elif key == 'High':\n",
    "            if i == 0:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = True, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Weitzman_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'High Damage Function', line = dict(color = 'green', dash='dash', width = 3), showlegend = True, legendgroup = 'High Damage Function')\n",
    "            else:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = False, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Weitzman_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'High Damage Function', line = dict(color = 'green', dash='dash', width = 3), showlegend = False, legendgroup = 'High Damage Function')\n",
    "\n",
    "\n",
    "        elif key == 'Low':\n",
    "            if i == 0:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = True, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Nordhaus_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'Low Damage Function', line = dict(color = 'red', dash='dashdot', width = 3), showlegend = True, legendgroup = 'Low Damage Function')\n",
    "            else:\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Original'][inds], row = 1, col = i + 1,\n",
    "                    name = 'Original Distribution', line = dict(color = '#1f77b4', width = 3), showlegend = False, legendgroup = 'Original Distribution')\n",
    "                fig.add_scatter(x = dom[inds] * 1000, y = data['Nordhaus_year' + str(year)][inds], row = 1, col = i + 1,\n",
    "                    name = 'Low Damage Function', line = dict(color = 'red', dash='dashdot', width = 3), showlegend = False, legendgroup = 'Low Damage Function')\n",
    "\n",
    "    fig['layout'].update(title = key + \" Damage Specification\", showlegend = True, titlefont = dict(size = 20), height = 400)\n",
    "\n",
    "    for i in range(len(years)):\n",
    "\n",
    "        fig['layout']['yaxis{}'.format(i+1)].update(showgrid = False)\n",
    "        fig['layout']['xaxis{}'.format(i+1)].update(showgrid = False)\n",
    "\n",
    "    fig['layout']['yaxis1'].update(title=go.layout.yaxis.Title(\n",
    "                                    text=\"Probability Density\", font=dict(size=16)))\n",
    "    fig['layout']['xaxis2'].update(title=go.layout.xaxis.Title(\n",
    "                                    text=\"Climate Sensitivity\", font=dict(size=16)), showgrid = False)\n",
    "\n",
    "    fig = go.FigureWidget(fig)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityPlot(damageSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCCDecomposePlot(key = 'Weighted'):\n",
    "\n",
    "    if key == 'Low':\n",
    "\n",
    "        data = SCCs\n",
    "        x1, y1, x2, y2, x3, y3 = 60, 195, 93, 330, 96, 100\n",
    "\n",
    "    elif key == 'Weighted':\n",
    "\n",
    "        data = SCCs\n",
    "        x1, y1, x2, y2, x3, y3 = 60, 320, 80, 315, 90, 350\n",
    "\n",
    "    elif key == 'High':\n",
    "\n",
    "        data = SCCs\n",
    "        x1, y1, x2, y2, x3, y3 = 60, 340, 93, 495, 96, 430\n",
    "\n",
    "\n",
    "    total_SCC = np.array(data['SCC'])\n",
    "    external_SCC = np.array(data['SCC2'])\n",
    "    uncertainty_SCC = np.array(data['SCC3'])\n",
    "    private_SCC = np.array(data['SCC1'])\n",
    "    x = np.linspace(0,100,400)\n",
    "\n",
    "    total = go.Scatter(x = x, y = total_SCC,\n",
    "                   name = 'Total', line = dict(color = '#1f77b4', dash = 'solid', width = 3),\\\n",
    "                       showlegend = False)\n",
    "    external = go.Scatter(x = x, y = external_SCC,\n",
    "                   name = 'Ambiguity', line = dict(color = 'red', dash = 'dot', width = 3),\\\n",
    "                          showlegend = False)\n",
    "    uncertainty = go.Scatter(x = x, y = uncertainty_SCC,\n",
    "                   name = 'No Ambiguity', line = dict(color = 'green', dash = 'dashdot', width = 3),\\\n",
    "                             showlegend = False)\n",
    "    private = go.Scatter(x = x, y = private_SCC,\n",
    "                   name = 'Private', line = dict(color = 'black', width = 3),\\\n",
    "                         showlegend = False)\n",
    "\n",
    "    annotations=[dict(x=x1, y=y1, text=\"Total\", textangle=0, ax=-100,\n",
    "                ay=-75, font=dict(color=\"black\", size=12), arrowcolor=\"black\",\n",
    "                arrowsize=3, arrowwidth=1, arrowhead=1),\n",
    "\n",
    "                dict(x=x2, y=y2, text=\"Ambiguity\", textangle=0, ax=-100,\n",
    "                ay=0, font=dict(color=\"black\", size=12), arrowcolor=\"black\",\n",
    "                arrowsize=3, arrowwidth=1, arrowhead=1),\n",
    "\n",
    "                dict(x=x3, y=y3, text=\"No Ambiguity\", textangle=0, ax=-80,\n",
    "                ay=80, font=dict(color=\"black\", size=12), arrowcolor=\"black\",\n",
    "                arrowsize=3, arrowwidth=1, arrowhead=1)]\n",
    "\n",
    "    layout = dict(title = 'Social Cost of Carbon, {} Damage Specification'.format(key),\n",
    "                  titlefont = dict(size = 20),\n",
    "                  xaxis = go.layout.XAxis(title=go.layout.xaxis.Title(\n",
    "                                    text='Years', font=dict(size=16)),\n",
    "                                         tickfont=dict(size=12), showgrid = False),\n",
    "                  yaxis = go.layout.YAxis(title=go.layout.yaxis.Title(\n",
    "                                    text='Dollars per Ton of Carbon', font=dict(size=16)),\n",
    "                                         tickfont=dict(size=12), showgrid = False), \n",
    "                  annotations=annotations\n",
    "                  )\n",
    "\n",
    "    fig = dict(data = [total, external, uncertainty], layout = layout)\n",
    "    iplot(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCCDecomposePlot(damageSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emissionPlot(damageSpec, Î¾):\n",
    "\n",
    "    colors = {'High': 'red', 'Low': 'green', 'Weighted': '#1f77b4'}\n",
    "    lines = {'Averse': 'solid', \"Neutral\": 'dashdot'}\n",
    "\n",
    "    # damageSpecs = ['High', 'Low', 'Weighted']\n",
    "    # aversionSpecs = ['Averse', 'Neutral']\n",
    "    # colors = ['green', '#1f77b4', 'red']\n",
    "    # lines = ['solid', 'dashdot'] \n",
    "\n",
    "    x = np.linspace(0, 100, 400)\n",
    "    data = []\n",
    "\n",
    "    data.append(go.Scatter(x = x, y = e_hists[:,0], name = damageSpec +  ' Damage w/ Î¾= {}'.format(Î¾),\n",
    "        line = dict(width = 2, dash = 'solid', color = colors[damageSpec]), showlegend = True))\n",
    "\n",
    "    layout = dict(title = 'Emissions Plot with {} Damage Setting, Î¾ = {}'.format(damageSpec, Î¾),\n",
    "      titlefont = dict(size = 20),\n",
    "      xaxis = go.layout.XAxis(title=go.layout.xaxis.Title(\n",
    "                        text='Years', font=dict(size=16)),\n",
    "                             tickfont=dict(size=12), showgrid = False, showline = True),\n",
    "      yaxis = go.layout.YAxis(title=go.layout.yaxis.Title(\n",
    "                        text='Gigatons of Carbon', font=dict(size=16)),\n",
    "                             tickfont=dict(size=12), showgrid = False),\n",
    "      legend = dict(orientation = 'h', y = 1.15)\n",
    "      )\n",
    "\n",
    "    fig = dict(data = data, layout = layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissionPlot(damageSpec, Î¾p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
